{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the method developed in the other notebook \"*Classifying sources with the WHAV\\* diagram*\" can we successfully classify spaxels in SAMI galaxies? \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.visualization import hist\n",
    "\n",
    "from spaxelsleuth.loaddata.lzifu import load_lzifu_galaxies\n",
    "from spaxelsleuth.loaddata.sami import load_sami_galaxies\n",
    "from spaxelsleuth.plotting.plottools import plot_empty_BPT_diagram\n",
    "from spaxelsleuth.plotting.plottools import vmin_fn, vmax_fn, label_fn, cmap_fn, fname_fn\n",
    "from spaxelsleuth.plotting.plottools import bpt_colours, bpt_labels, whav_colors, whav_labels\n",
    "from spaxelsleuth.plotting.plottools import morph_labels, morph_ticks\n",
    "from spaxelsleuth.plotting.plottools import ncomponents_labels, ncomponents_colours\n",
    "from spaxelsleuth.plotting.plottools import component_labels, component_colours\n",
    "from spaxelsleuth.plotting.plotgalaxies import plot2dhistcontours, plot2dscatter, plot2dcontours\n",
    "from spaxelsleuth.plotting.plot2dmap import plot2dmap\n",
    "from spaxelsleuth.plotting.sdssimg import plot_sdss_image\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import rc, rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "rc(\"text\", usetex=False)\n",
    "rc(\"font\",**{\"family\": \"serif\", \"size\": 14})\n",
    "rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "rcParams[\"savefig.format\"] = \"pdf\"\n",
    "plt.ion()\n",
    "plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "fig_path = \"/priv/meggs3/u5708159/SAMI/figs/paper/\"\n",
    "savefigs = True\n",
    "bin_type = \"default\"    # Options: \"default\" or \"adaptive\" for Voronoi binning\n",
    "ncomponents = \"recom\"   # Options: \"1\" or \"recom\"\n",
    "eline_SNR_min = 3       # Minimum S/N of emission lines to accept\n",
    "plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: in load_sami_galaxies: NOT correcting Halpha and HALPHA EW for extinction!\n"
     ]
    }
   ],
   "source": [
    "# Load the sample\n",
    "df = load_sami_galaxies(ncomponents=ncomponents,\n",
    "                        bin_type=bin_type,\n",
    "                        eline_SNR_min=eline_SNR_min, \n",
    "                        vgrad_cut=False,\n",
    "                        correct_extinction=False,\n",
    "                        sigma_gas_SNR_cut=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LZIFU DataFrame for all galaxies in the LZIFU subsample...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u5708159/python/Modules/spaxelsleuth/loaddata/linefns.py:78: RuntimeWarning: invalid value encountered in add\n",
      "  return -0.943 * ratio_y_vals**4 - 0.450 * ratio_y_vals**3 + 0.408 * ratio_y_vals**2 - 0.610 * ratio_y_vals - 0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: in load_lzifu_galaxy: NOT correcting Halpha and HALPHA EW for extinction!\n"
     ]
    }
   ],
   "source": [
    "# Load the LZIFU galaxies\n",
    "df_lzifu = load_lzifu_galaxies(ncomponents=ncomponents,\n",
    "                              bin_type=bin_type,\n",
    "                              eline_SNR_min=5, \n",
    "                              vgrad_cut=False,\n",
    "                              correct_extinction=False,\n",
    "                              sigma_gas_SNR_cut=True)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots for paper: histograms showing log N2, EW, $\\Delta\\sigma$ for each BPT category separately\n",
    "---\n",
    "\n",
    "Histograms of each quantity, separated by BPT category, for \n",
    "* LZIFU subset (individual components)\n",
    "* SAMI dataset (based on total line fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "#//////////////////////////////////////////////////////////////////////////////\n",
    "# Make a copy of the LZIFU data frame where the fluxes/classifications for \n",
    "# all components are stored in \"component 0\"\n",
    "df_lzifu_comp0 = None\n",
    "for ii in [0, 1, 2]:\n",
    "    df_this_component = df_lzifu[~df_lzifu[f\"sigma_gas - sigma_* (component {ii})\"].isna()]\n",
    "    # # print(df_this_component[print_cols])\n",
    "    \n",
    "    # Drop all columns that are NOT this component\n",
    "    other_components = [cc for cc in [0, 1, 2] if cc != ii]\n",
    "    cols_to_drop = [c for c in df_this_component.columns if f\"(total)\" in c]\n",
    "    for cc in other_components:\n",
    "        cols_to_drop += [c for c in df_this_component.columns if f\"(component {cc})\" in c]\n",
    "    df_this_component = df_this_component.drop(columns=cols_to_drop)\n",
    "    # print(\"---------------------------------------------------\")\n",
    "    # print(df_this_component[f\"sigma_gas - sigma_* (component {ii})\"])\n",
    "\n",
    "    # Rename columns to have suffix \"component 0\"\n",
    "    if ii != 0:\n",
    "        cols_to_rename = [c for c in df_this_component.columns if c.endswith(f\"(component {ii})\")]\n",
    "        new_col_names = [c.split(f\"(component {ii})\")[0] + \"(component 0)\" for c in cols_to_rename]\n",
    "        rename_dict = dict(zip(cols_to_rename, new_col_names))\n",
    "        df_this_component = df_this_component.rename(columns=rename_dict)\n",
    "    # print(\"---------------------------------------------------\")\n",
    "    # print(df_this_component[f\"sigma_gas - sigma_* (component 0)\"])\n",
    "\n",
    "    # Merge \n",
    "    if df_lzifu_comp0 is None:\n",
    "        df_lzifu_comp0 = df_this_component.copy()\n",
    "    else:\n",
    "        df_lzifu_comp0 = df_lzifu_comp0.append(df_this_component)\n",
    "    # print(\"---------------------------------------------------\")\n",
    "    # print(df_lzifu_comp0[f\"sigma_gas - sigma_* (component 0)\"])\n",
    "\n",
    "# Drop bad rows\n",
    "df_lzifu_comp0.loc[:, \"Good?\"] = ~df_lzifu_comp0[f\"sigma_gas - sigma_* (component 0)\"].isna() & ~df_lzifu_comp0[f\"log HALPHA EW (component 0)\"].isna()\n",
    "cond = df_lzifu_comp0[\"Good?\"] == 1.0\n",
    "df_lzifu_comp0 = df_lzifu_comp0[cond]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e8af2256ae49d2bbf6da26e46f5ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/astropy/visualization/hist.py:72: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  return ax.hist(x, bins, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06ba1a03996435aaef8d213a90d2a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/astropy/visualization/hist.py:72: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  return ax.hist(x, bins, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08af1e7e1cb4fef950b25bdd969e69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/astropy/visualization/hist.py:72: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  return ax.hist(x, bins, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9a702140174d1aa7266c2465f4295e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/astropy/visualization/hist.py:72: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  return ax.hist(x, bins, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1038c7b92a74a80bd4d52770fde52c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/astropy/visualization/hist.py:72: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  return ax.hist(x, bins, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Histograms showing Halpha EW as a function of spectral category\n",
    "col = \"log HALPHA EW (component 0)\"\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "for cat, colour in zip(bpt_labels, bpt_colours):\n",
    "    df_cat = df_lzifu_comp0[df_lzifu_comp0[\"BPT (component 0)\"] == cat]\n",
    "    N = df_cat.loc[~np.isnan(df_cat[col])].shape[0]\n",
    "    hist(df_cat[col], range=(vmin_fn(col), vmax_fn(col)), bins=\"scott\", histtype=\"step\", color=colour, label=f\"{cat} (N = {N:d})\", normed=True)\n",
    "ax.set_xlabel(label_fn(col))\n",
    "ax.set_ylabel(r\"$N$ (normalised)\")\n",
    "ax.set_title(\"Individual components\")\n",
    "ax.grid()\n",
    "ax.legend(fontsize=\"x-small\")\n",
    "ax.autoscale(axis=\"x\", tight=True, enable=True)\n",
    "if savefigs:\n",
    "    fig.savefig(os.path.join(fig_path, f\"lzifu_subset_hist_{fname_fn(col)}_indv.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    # Histograms showing Halpha EW as a function of spectral category\n",
    "col = \"log HALPHA EW (total)\"\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "for cat, colour in zip(bpt_labels, bpt_colours):\n",
    "    df_cat = df_lzifu[df_lzifu[\"BPT (total)\"] == cat]\n",
    "    N = df_cat.loc[~np.isnan(df_cat[col])].shape[0]\n",
    "    hist(df_cat[col], range=(vmin_fn(col), vmax_fn(col)), bins=\"scott\", histtype=\"step\", color=colour, label=f\"{cat} (N = {N:d})\", normed=True)\n",
    "ax.set_xlabel(label_fn(col))\n",
    "ax.set_ylabel(r\"$N$ (normalised)\")\n",
    "ax.set_title(\"Spaxels\")\n",
    "ax.grid()\n",
    "ax.legend(fontsize=\"x-small\")\n",
    "ax.autoscale(axis=\"x\", tight=True, enable=True)\n",
    "if savefigs:\n",
    "    fig.savefig(os.path.join(fig_path, f\"lzifu_subset_hist_{fname_fn(col)}_total.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    \n",
    "# Histograms showing delta sigma as a function of spectral category\n",
    "col = \"sigma_gas - sigma_* (component 0)\"\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "for cat, colour in zip(bpt_labels, bpt_colours):\n",
    "    df_cat = df_lzifu_comp0[df_lzifu_comp0[\"BPT (component 0)\"] == cat]\n",
    "    N = df_cat.loc[~np.isnan(df_cat[col])].shape[0]\n",
    "    hist(df_cat[col], range=(vmin_fn(col), 400), bins=\"scott\", histtype=\"step\", color=colour, label=f\"{cat} (N = {N:d})\", normed=True)\n",
    "ax.set_xlabel(label_fn(col))\n",
    "ax.set_ylabel(r\"$N$ (normalised)\")\n",
    "ax.set_title(\"Individual components\")\n",
    "ax.grid()\n",
    "ax.legend(fontsize=\"x-small\")\n",
    "ax.autoscale(axis=\"x\", tight=True, enable=True)\n",
    "if savefigs:\n",
    "    fig.savefig(os.path.join(fig_path, f\"lzifu_subset_hist_{fname_fn(col)}.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "# Histograms showing log N2 as a function of spectral category - INDIVIDUAL COMPONENTS\n",
    "col = \"log N2 (component 0)\"\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "for cat, colour in zip(bpt_labels, bpt_colours):\n",
    "    df_cat = df_lzifu_comp0[df_lzifu_comp0[\"BPT (component 0)\"] == cat]\n",
    "    N = df_cat.loc[~np.isnan(df_cat[col])].shape[0]\n",
    "    hist(df_cat[col], range=(vmin_fn(col), vmax_fn(col)), bins=\"scott\", histtype=\"step\", color=colour, label=f\"{cat} (N = {N:d})\", normed=True)\n",
    "ax.axvline(-0.35, color=\"k\", linestyle=\"--\")\n",
    "ax.axvline(-0.20, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(label_fn(col))\n",
    "ax.set_ylabel(r\"$N$ (normalised)\")\n",
    "ax.set_title(\"Individual components\")\n",
    "ax.grid()\n",
    "ax.legend(fontsize=\"x-small\")\n",
    "ax.autoscale(axis=\"x\", tight=True, enable=True)\n",
    "if savefigs:\n",
    "    fig.savefig(os.path.join(fig_path, f\"lzifu_subset_hist_{fname_fn(col)}_indv.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "# Histograms showing log N2 as a function of spectral category - SPAXELS\n",
    "col = \"log N2 (total)\"\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "for cat, colour in zip(bpt_labels, bpt_colours):\n",
    "    df_cat = df_lzifu[df_lzifu[\"BPT (total)\"] == cat]\n",
    "    N = df_cat.loc[~np.isnan(df_cat[col])].shape[0]\n",
    "    hist(df_cat[col], range=(vmin_fn(col), vmax_fn(col)), bins=\"scott\", histtype=\"step\", color=colour, label=f\"{cat} (N = {N:d})\", normed=True)\n",
    "ax.axvline(-0.35, color=\"k\", linestyle=\"--\")\n",
    "ax.axvline(-0.20, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(label_fn(col))\n",
    "ax.set_ylabel(r\"$N$ (normalised)\")\n",
    "ax.set_title(\"Spaxels\")\n",
    "ax.grid()\n",
    "ax.legend(fontsize=\"x-small\")\n",
    "ax.autoscale(axis=\"x\", tight=True, enable=True)\n",
    "if savefigs:\n",
    "    fig.savefig(os.path.join(fig_path, f\"lzifu_subset_hist_{fname_fn(col)}_total.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables: comparison between classification systems\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n################################################################################\\n# Testing our classifiction system\\n################################################################################\\ndf_lzifu[\"WHAV*\"] = \"Unknown\"  # Initialise everything to \"unknown\"\\n\\n#///////////////////////////////////////////////////////////////////////////////\\n# Step 1: filter out evolved stars\\ncond = df_lzifu[\"HALPHA EW (total)\"] <= 3\\ndf_lzifu.loc[cond, \"WHAV*\"] = \"HOLMES\"\\ncond_remainder = df_lzifu[\"WHAV*\"] == \"Unknown\"\\n\\n#///////////////////////////////////////////////////////////////////////////////\\n# Step 2: use the N2 ratio to divide into SF, mixed and AGN/evolved stars/shocks\\n# Because we used the TOTAL N2 ratio in each spaxel to determine these boundaries, these categories are representative of the DOMINANT ionisation mechanism in each spaxel.\\ncond_SF = cond_remainder & (df_lzifu[\"log N2 (total)\"] < -0.35)\\ncond_Mixing = cond_remainder & (df_lzifu[\"log N2 (total)\"] >= -0.35) & (df_lzifu[\"log N2 (total)\"] < -0.2)\\ncond_AGN = cond_remainder & (df_lzifu[\"log N2 (total)\"] >= -0.2)\\ncond_no_N2 = np.isnan(df_lzifu[\"log N2 (total)\"])\\n\\ndf_lzifu.loc[cond_SF, \"WHAV*\"] = \"SF\" \\ndf_lzifu.loc[cond_Mixing, \"WHAV*\"] = \"Mixing\"\\ndf_lzifu.loc[cond_AGN, \"WHAV*\"] = \"AGN/HOLMES/shocks\"\\ndf_lzifu.loc[cond_no_N2, \"WHAV*\"] = \"No N2\"\\n\\n#///////////////////////////////////////////////////////////////////////////////\\n# For convenience: mark components as possible HOLMES \\n# Question: how confident can we be that these are ALWAYS HOLMES? how common are components from e.g. LLAGN?\\nfor ii in range(3):\\n    cond_possible_HOLMES = cond_AGN & (df_lzifu[f\"HALPHA EW (component {ii})\"] < 3) & (df_lzifu[f\"sigma_gas - sigma_* (component {ii})\"] < 0)\\n    df_lzifu.loc[cond_possible_HOLMES, f\"Possible HOLMES (component {ii})\"] = True\\n    df_lzifu.loc[~cond_possible_HOLMES, f\"Possible HOLMES (component {ii})\"] = False\\n    \\n#///////////////////////////////////////////////////////////////////////////////\\n# For convenience: mark components as being kinematically disturbed (by 3sigma)\\nfor ii in range(3):\\n    cond_kinematically_disturbed = df_lzifu[f\"sigma_gas - sigma_* (component {ii})\"] - 3 * df_lzifu[f\"sigma_gas - sigma_* error (component {ii})\"] > 0\\n    df_lzifu.loc[cond_kinematically_disturbed, f\"Kinematically disturbed (component {ii})\"] = True\\n    df_lzifu.loc[~cond_kinematically_disturbed, f\"Kinematically disturbed (component {ii})\"] = False\\n    \\n################################################################################\\n# Repeat for SAMI sample\\n################################################################################\\ndf[\"WHAV*\"] = \"Unknown\"  # Initialise everything to \"unknown\"\\n\\n#///////////////////////////////////////////////////////////////////////////////\\n# Step 1: filter out evolved stars\\ncond = df[\"HALPHA EW (total)\"] <= 3\\ndf.loc[cond, \"WHAV*\"] = \"HOLMES\"\\ncond_remainder = df[\"WHAV*\"] == \"Unknown\"\\n\\n#///////////////////////////////////////////////////////////////////////////////\\n# Step 2: use the N2 ratio to divide into SF, mixed and AGN/evolved stars/shocks\\n# Because we used the TOTAL N2 ratio in each spaxel to determine these boundaries, these categories are representative of the DOMINANT ionisation mechanism in each spaxel.\\ncond_SF = cond_remainder & (df[\"log N2 (total)\"] < -0.35)\\ncond_Mixing = cond_remainder & (df[\"log N2 (total)\"] >= -0.35) & (df[\"log N2 (total)\"] < -0.2)\\ncond_AGN = cond_remainder & (df[\"log N2 (total)\"] >= -0.2)\\ncond_no_N2 = np.isnan(df[\"log N2 (total)\"])\\n\\ndf.loc[cond_SF, \"WHAV*\"] = \"SF\" \\ndf.loc[cond_Mixing, \"WHAV*\"] = \"Mixing\"\\ndf.loc[cond_AGN, \"WHAV*\"] = \"AGN/HOLMES/shocks\"\\ndf.loc[cond_no_N2, \"WHAV*\"] = \"No N2\"\\n\\n#///////////////////////////////////////////////////////////////////////////////\\n# For convenience: mark components as possible HOLMES \\n# Question: how confident can we be that these are ALWAYS HOLMES? how common are components from e.g. LLAGN?\\nfor ii in range(3):\\n    cond_possible_HOLMES = cond_AGN & (df[f\"HALPHA EW (component {ii})\"] < 3) & (df[f\"sigma_gas - sigma_* (component {ii})\"] < 0)\\n    df.loc[cond_possible_HOLMES, f\"Possible HOLMES (component {ii})\"] = True\\n    df.loc[~cond_possible_HOLMES, f\"Possible HOLMES (component {ii})\"] = False\\n    \\n#///////////////////////////////////////////////////////////////////////////////\\n# For convenience: mark components as being kinematically disturbed (by 3sigma)\\nfor ii in range(3):\\n    cond_kinematically_disturbed = df[f\"sigma_gas - sigma_* (component {ii})\"] - 3 * df[f\"sigma_gas - sigma_* error (component {ii})\"] > 0\\n    df.loc[cond_kinematically_disturbed, f\"Kinematically disturbed (component {ii})\"] = True\\n    df.loc[~cond_kinematically_disturbed, f\"Kinematically disturbed (component {ii})\"] = False\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "################################################################################\n",
    "# Testing our classifiction system\n",
    "################################################################################\n",
    "df_lzifu[\"WHAV*\"] = \"Unknown\"  # Initialise everything to \"unknown\"\n",
    "\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# Step 1: filter out evolved stars\n",
    "cond = df_lzifu[\"HALPHA EW (total)\"] <= 3\n",
    "df_lzifu.loc[cond, \"WHAV*\"] = \"HOLMES\"\n",
    "cond_remainder = df_lzifu[\"WHAV*\"] == \"Unknown\"\n",
    "\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# Step 2: use the N2 ratio to divide into SF, mixed and AGN/evolved stars/shocks\n",
    "# Because we used the TOTAL N2 ratio in each spaxel to determine these boundaries, these categories are representative of the DOMINANT ionisation mechanism in each spaxel.\n",
    "cond_SF = cond_remainder & (df_lzifu[\"log N2 (total)\"] < -0.35)\n",
    "cond_Mixing = cond_remainder & (df_lzifu[\"log N2 (total)\"] >= -0.35) & (df_lzifu[\"log N2 (total)\"] < -0.2)\n",
    "cond_AGN = cond_remainder & (df_lzifu[\"log N2 (total)\"] >= -0.2)\n",
    "cond_no_N2 = np.isnan(df_lzifu[\"log N2 (total)\"])\n",
    "\n",
    "df_lzifu.loc[cond_SF, \"WHAV*\"] = \"SF\" \n",
    "df_lzifu.loc[cond_Mixing, \"WHAV*\"] = \"Mixing\"\n",
    "df_lzifu.loc[cond_AGN, \"WHAV*\"] = \"AGN/HOLMES/shocks\"\n",
    "df_lzifu.loc[cond_no_N2, \"WHAV*\"] = \"No N2\"\n",
    "\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# For convenience: mark components as possible HOLMES \n",
    "# Question: how confident can we be that these are ALWAYS HOLMES? how common are components from e.g. LLAGN?\n",
    "for ii in range(3):\n",
    "    cond_possible_HOLMES = cond_AGN & (df_lzifu[f\"HALPHA EW (component {ii})\"] < 3) & (df_lzifu[f\"sigma_gas - sigma_* (component {ii})\"] < 0)\n",
    "    df_lzifu.loc[cond_possible_HOLMES, f\"Possible HOLMES (component {ii})\"] = True\n",
    "    df_lzifu.loc[~cond_possible_HOLMES, f\"Possible HOLMES (component {ii})\"] = False\n",
    "    \n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# For convenience: mark components as being kinematically disturbed (by 3sigma)\n",
    "for ii in range(3):\n",
    "    cond_kinematically_disturbed = df_lzifu[f\"sigma_gas - sigma_* (component {ii})\"] - 3 * df_lzifu[f\"sigma_gas - sigma_* error (component {ii})\"] > 0\n",
    "    df_lzifu.loc[cond_kinematically_disturbed, f\"Kinematically disturbed (component {ii})\"] = True\n",
    "    df_lzifu.loc[~cond_kinematically_disturbed, f\"Kinematically disturbed (component {ii})\"] = False\n",
    "    \n",
    "################################################################################\n",
    "# Repeat for SAMI sample\n",
    "################################################################################\n",
    "df[\"WHAV*\"] = \"Unknown\"  # Initialise everything to \"unknown\"\n",
    "\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# Step 1: filter out evolved stars\n",
    "cond = df[\"HALPHA EW (total)\"] <= 3\n",
    "df.loc[cond, \"WHAV*\"] = \"HOLMES\"\n",
    "cond_remainder = df[\"WHAV*\"] == \"Unknown\"\n",
    "\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# Step 2: use the N2 ratio to divide into SF, mixed and AGN/evolved stars/shocks\n",
    "# Because we used the TOTAL N2 ratio in each spaxel to determine these boundaries, these categories are representative of the DOMINANT ionisation mechanism in each spaxel.\n",
    "cond_SF = cond_remainder & (df[\"log N2 (total)\"] < -0.35)\n",
    "cond_Mixing = cond_remainder & (df[\"log N2 (total)\"] >= -0.35) & (df[\"log N2 (total)\"] < -0.2)\n",
    "cond_AGN = cond_remainder & (df[\"log N2 (total)\"] >= -0.2)\n",
    "cond_no_N2 = np.isnan(df[\"log N2 (total)\"])\n",
    "\n",
    "df.loc[cond_SF, \"WHAV*\"] = \"SF\" \n",
    "df.loc[cond_Mixing, \"WHAV*\"] = \"Mixing\"\n",
    "df.loc[cond_AGN, \"WHAV*\"] = \"AGN/HOLMES/shocks\"\n",
    "df.loc[cond_no_N2, \"WHAV*\"] = \"No N2\"\n",
    "\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# For convenience: mark components as possible HOLMES \n",
    "# Question: how confident can we be that these are ALWAYS HOLMES? how common are components from e.g. LLAGN?\n",
    "for ii in range(3):\n",
    "    cond_possible_HOLMES = cond_AGN & (df[f\"HALPHA EW (component {ii})\"] < 3) & (df[f\"sigma_gas - sigma_* (component {ii})\"] < 0)\n",
    "    df.loc[cond_possible_HOLMES, f\"Possible HOLMES (component {ii})\"] = True\n",
    "    df.loc[~cond_possible_HOLMES, f\"Possible HOLMES (component {ii})\"] = False\n",
    "    \n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# For convenience: mark components as being kinematically disturbed (by 3sigma)\n",
    "for ii in range(3):\n",
    "    cond_kinematically_disturbed = df[f\"sigma_gas - sigma_* (component {ii})\"] - 3 * df[f\"sigma_gas - sigma_* error (component {ii})\"] > 0\n",
    "    df.loc[cond_kinematically_disturbed, f\"Kinematically disturbed (component {ii})\"] = True\n",
    "    df.loc[~cond_kinematically_disturbed, f\"Kinematically disturbed (component {ii})\"] = False\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unknown', 'SF + no wind', 'Mixing + no wind', 'AGN + no wind',\n",
       "       'SF + wind', 'HOLMES', 'Mixing + wind', 'AGN + wind',\n",
       "       'AGN + HOLMES + no wind', 'AGN + HOLMES + wind'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lzifu[\"WHAV*\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the high-S/N LZIFU subset:\n",
      "31.76630286387431\\% of spaxels can be classified using the BPT\n",
      "90.15704110529478\\% of spaxels can be classified using the new method\n",
      "\n",
      "In the whole SAMI sample:\n",
      "51.750623984113055\\% of spaxels can be classified using the BPT\n",
      "89.72571902692484\\% of spaxels can be classified using the new method\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################################\n",
    "# How many spaxels can each method successfully classify?\n",
    "#############################################################################################################\n",
    "print(\"In the high-S/N LZIFU subset:\")\n",
    "cond_has_emission_lines = df_lzifu[\"Number of components\"] >= 1\n",
    "frac_unclassified_bpt = 1 - df_lzifu[cond_has_emission_lines & (df_lzifu[\"BPT (total)\"] == \"Not classified\")].shape[0] / df_lzifu[cond_has_emission_lines].shape[0]\n",
    "# frac_unclassified_whan = 1 - df_lzifu[cond_has_emission_lines & (df_lzifu[\"WHAN\"] == \"No N2\")].shape[0] / df_lzifu[cond_has_emission_lines].shape[0]\n",
    "frac_unclassified_whav = 1 - df_lzifu[cond_has_emission_lines & (df_lzifu[\"WHAV*\"] == \"Unknown\")].shape[0] / df_lzifu[cond_has_emission_lines].shape[0]\n",
    "print(f\"{frac_unclassified_bpt * 100}\\% of spaxels can be classified using the BPT\")\n",
    "# print(f\"{frac_unclassified_whan * 100}\\% of spaxels can be classified using the WHAN\")\n",
    "print(f\"{frac_unclassified_whav * 100}\\% of spaxels can be classified using the new method\")\n",
    "\n",
    "print(\"\\nIn the whole SAMI sample:\")\n",
    "cond_has_emission_lines = df[\"Number of components\"] >= 1\n",
    "frac_unclassified_bpt = 1 - df[cond_has_emission_lines & (df[\"BPT (total)\"] == \"Not classified\")].shape[0] / df[cond_has_emission_lines].shape[0]\n",
    "# frac_unclassified_whan = 1 - df[cond_has_emission_lines & (df[\"WHAN\"] == \"No N2\")].shape[0] / df[cond_has_emission_lines].shape[0]\n",
    "frac_unclassified_whav = 1 - df[cond_has_emission_lines & (df[\"WHAV*\"] == \"Unknown\")].shape[0] / df[cond_has_emission_lines].shape[0]\n",
    "print(f\"{frac_unclassified_bpt * 100}\\% of spaxels can be classified using the BPT\")\n",
    "# print(f\"{frac_unclassified_whan * 100}\\% of spaxels can be classified using the WHAN\")\n",
    "print(f\"{frac_unclassified_whav * 100}\\% of spaxels can be classified using the new method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    & SF             & Composite      & Seyfert        & LINER          & Ambiguous      & Not classified \\\\\n",
      "SF                  \t&      94.13\\%\t&      21.08\\%\t&       1.79\\%\t&       0.00\\%\t&      70.78\\%\t&       4.92\\%\\\\\n",
      "Mixing              \t&       5.83\\%\t&      65.57\\%\t&       5.46\\%\t&       0.20\\%\t&       8.68\\%\t&       3.92\\%\\\\\n",
      "AGN/HOLMES/shocks   \t&       0.01\\%\t&      10.13\\%\t&      66.32\\%\t&      27.21\\%\t&       9.99\\%\t&       1.74\\%\\\\\n",
      "HOLMES              \t&       0.03\\%\t&       3.21\\%\t&      26.43\\%\t&      72.59\\%\t&      10.54\\%\t&       5.58\\%\\\\\n",
      "No N2               \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&      83.84\\%\\\\\n",
      "Unknown             \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\\\\\n",
      "Total               &           27339 &            7404 &            1063 &            1470 &            3443 &          463155 \\\\\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################################\n",
    "# Table: comparison between BPT- and N2- and \\ewha{}-based spectral categories for the LZIFU high-SN subset.\n",
    "#############################################################################################################\n",
    "s = f\"{'':20s}\"\n",
    "s_tot = f\"{'Total':20s}\"\n",
    "for bpt in [\"SF\", \"Composite\", \"Seyfert\", \"LINER\", \"Ambiguous\", \"Not classified\"]:\n",
    "    s += f\"& {bpt:15s}\"\n",
    "    N_bpt_tot =         df_lzifu[(df_lzifu[\"BPT (total)\"] == bpt)].shape[0]\n",
    "    s_tot += f\"& {N_bpt_tot:15d} \"\n",
    "s += \"\\\\\\\\\"\n",
    "s_tot += \"\\\\\\\\\"\n",
    "print(s)\n",
    "for whav_cat in [\"SF\", \"Mixing\", \"AGN/HOLMES/shocks\", \"HOLMES\", \"No N2\", \"Unknown\"]:\n",
    "    s = f\"{whav_cat:20s}\"\n",
    "    for bpt in [\"SF\", \"Composite\", \"Seyfert\", \"LINER\", \"Ambiguous\", \"Not classified\"]:\n",
    "        N_bpt_tot =         df_lzifu[(df_lzifu[\"BPT (total)\"] == bpt)].shape[0]\n",
    "        N_bpt_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == bpt) & (df_lzifu[\"WHAN\"] == whav_cat)].shape[0]\n",
    "        s += f\"\\t& {N_bpt_in_this_cat / N_bpt_tot * 100:10.2f}\\%\"\n",
    "    s += \"\\\\\\\\\"\n",
    "    print(s)\n",
    "print(s_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    & SF             & Composite      & Seyfert        & LINER          & Ambiguous      & Not classified \\\\\n",
      "SF                  \t&      96.96\\%\t&      15.35\\%\t&       7.22\\%\t&       0.01\\%\t&      79.62\\%\t&       7.47\\%\\\\\n",
      "Mixing              \t&       3.02\\%\t&      66.29\\%\t&      15.99\\%\t&       1.28\\%\t&       5.92\\%\t&       3.61\\%\\\\\n",
      "AGN/HOLMES/shocks   \t&       0.00\\%\t&      11.97\\%\t&      56.87\\%\t&      21.36\\%\t&       5.64\\%\t&       1.67\\%\\\\\n",
      "HOLMES              \t&       0.02\\%\t&       6.39\\%\t&      19.92\\%\t&      77.35\\%\t&       8.82\\%\t&       6.38\\%\\\\\n",
      "No N2               \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&      80.87\\%\\\\\n",
      "Unknown             \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\\\\\n",
      "Total               &          301858 &           35284 &            3353 &            8919 &           31054 &         1459687 \\\\\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################################\n",
    "# Table: comparison between BPT- and N2- and \\ewha{}-based spectral categories for the entire SAMI sample.\n",
    "#############################################################################################################\n",
    "s = f\"{'':20s}\"\n",
    "s_tot = f\"{'Total':20s}\"\n",
    "for bpt in [\"SF\", \"Composite\", \"Seyfert\", \"LINER\", \"Ambiguous\", \"Not classified\"]:\n",
    "    s += f\"& {bpt:15s}\"\n",
    "    N_bpt_tot =         df[(df[\"BPT (total)\"] == bpt)].shape[0]\n",
    "    s_tot += f\"& {N_bpt_tot:15d} \"\n",
    "s += \"\\\\\\\\\"\n",
    "s_tot += \"\\\\\\\\\"\n",
    "print(s)\n",
    "for whav_cat in [\"SF\", \"Mixing\", \"AGN/HOLMES/shocks\", \"HOLMES\", \"No N2\", \"Unknown\"]:\n",
    "    s = f\"{whav_cat:20s}\"\n",
    "    for bpt in [\"SF\", \"Composite\", \"Seyfert\", \"LINER\", \"Ambiguous\", \"Not classified\"]:\n",
    "        N_bpt_tot =         df[(df[\"BPT (total)\"] == bpt)].shape[0]\n",
    "        N_bpt_in_this_cat = df[(df[\"BPT (total)\"] == bpt) & (df[\"WHAN\"] == whav_cat)].shape[0]\n",
    "        s += f\"\\t& {N_bpt_in_this_cat / N_bpt_tot * 100:10.2f}\\%\"\n",
    "    s += \"\\\\\\\\\"\n",
    "    print(s)\n",
    "print(s_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################################################\n",
      "LZIFU SUBSET: STAR-FORMING SPAXELS\n",
      "############################################################################################\n",
      "Fraction of BPT-classified SF spaxels with a WHAN classification that agrees: 25733/27339 = 94.13%\n",
      "Fraction of BPT-classified SF spaxels with a WHAN classification that disagrees: 1606/27339 = 5.87%\n",
      "--------------------------------------------------------------------------------------------\n",
      "Of all BPT-classified SF spaxels:\n",
      "\t   0/27339 = 0.00% are in category 'Unknown'\n",
      "\t   9/27339 = 0.03% are in category 'HOLMES'\n",
      "\t25733/27339 = 94.13% are in category 'SF'\n",
      "\t1595/27339 = 5.83% are in category 'Mixing'\n",
      "\t   2/27339 = 0.01% are in category 'AGN/HOLMES/shocks'\n",
      "\t   0/27339 = 0.00% are in category 'No N2'\n",
      "\n",
      "############################################################################################\n",
      "LZIFU SUBSET: COMPOSITE SPAXELS\n",
      "############################################################################################\n",
      "Fraction of BPT-classified SF spaxels with a WHAN classification that agrees: 4855/7404 = 65.57%\n",
      "Fraction of BPT-classified SF spaxels with a WHAN classification that disagrees: 2549/7404 = 34.43%\n",
      "--------------------------------------------------------------------------------------------\n",
      "Of all BPT-classified Composite spaxels:\n",
      "\t   0/7404 = 0.00% are in category 'Unknown'\n",
      "\t 238/7404 = 3.21% are in category 'HOLMES'\n",
      "\t1561/7404 = 21.08% are in category 'SF'\n",
      "\t4855/7404 = 65.57% are in category 'Mixing'\n",
      "\t 750/7404 = 10.13% are in category 'AGN/HOLMES/shocks'\n",
      "\t   0/7404 = 0.00% are in category 'No N2'\n",
      "\n",
      "############################################################################################\n",
      "LZIFU SUBSET: SEYFERT SPAXELS\n",
      "############################################################################################\n",
      "Fraction of BPT-classified SF spaxels with a WHAN classification that agrees: 705/1063 = 66.32%\n",
      "Fraction of BPT-classified SF spaxels with a WHAN classification that disagrees: 358/1063 = 33.68%\n",
      "--------------------------------------------------------------------------------------------\n",
      "Of all BPT-classified Seyfert spaxels:\n",
      "\t   0/1063 = 0.00% are in category 'Unknown'\n",
      "\t 281/1063 = 26.43% are in category 'HOLMES'\n",
      "\t  19/1063 = 1.79% are in category 'SF'\n",
      "\t  58/1063 = 5.46% are in category 'Mixing'\n",
      "\t 705/1063 = 66.32% are in category 'AGN/HOLMES/shocks'\n",
      "\t   0/1063 = 0.00% are in category 'No N2'\n",
      "\n",
      "############################################################################################\n",
      "LZIFU SUBSET: LINER SPAXELS\n",
      "############################################################################################\n",
      "Fraction of BPT-classified SF spaxels with a WHAN classification that agrees: 400/1470 = 27.21%\n",
      "Fraction of BPT-classified SF spaxels with a WHAN classification that disagrees: 3/1470 = 0.20%\n",
      "--------------------------------------------------------------------------------------------\n",
      "Of all BPT-classified LINER spaxels:\n",
      "\t   0/1470 = 0.00% are in category 'Unknown'\n",
      "\t1067/1470 = 72.59% are in category 'HOLMES'\n",
      "\t   0/1470 = 0.00% are in category 'SF'\n",
      "\t   3/1470 = 0.20% are in category 'Mixing'\n",
      "\t 400/1470 = 27.21% are in category 'AGN/HOLMES/shocks'\n",
      "\t   0/1470 = 0.00% are in category 'No N2'\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Test: how many spaxels get mis-classified using our N2 criterion?\n",
    "################################################################################\n",
    "# What % of all BPT-classified SF spaxels are in a WHAN category that includes SF?\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: STAR-FORMING SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"SF\")].shape[0]\n",
    "N_agree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"SF\") & (df_lzifu[\"WHAN\"] == \"SF\")].shape[0]\n",
    "N_disagree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"SF\") & (df_lzifu[\"WHAN\"] != \"SF\")].shape[0]\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAN classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAN classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified SF spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in [\"Unknown\", \"HOLMES\", \"SF\", \"Mixing\", \"AGN/HOLMES/shocks\", \"No N2\"]:\n",
    "    N_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"SF\") & (df_lzifu[\"WHAN\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: COMPOSITE SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Composite\")].shape[0]\n",
    "N_agree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Composite\") & (df_lzifu[\"WHAN\"] == \"Mixing\")].shape[0]\n",
    "N_disagree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Composite\") & (df_lzifu[\"WHAN\"] != \"Mixing\")].shape[0]\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAN classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAN classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified Composite spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in [\"Unknown\", \"HOLMES\", \"SF\", \"Mixing\", \"AGN/HOLMES/shocks\", \"No N2\"]:\n",
    "    N_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Composite\") & (df_lzifu[\"WHAN\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: SEYFERT SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Seyfert\")].shape[0]\n",
    "N_agree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Seyfert\") & (df_lzifu[\"WHAN\"] == \"AGN/HOLMES/shocks\")].shape[0]\n",
    "N_disagree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Seyfert\") & (df_lzifu[\"WHAN\"] != \"AGN/HOLMES/shocks\")].shape[0]\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAN classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAN classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified Seyfert spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in [\"Unknown\", \"HOLMES\", \"SF\", \"Mixing\", \"AGN/HOLMES/shocks\", \"No N2\"]:\n",
    "    N_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Seyfert\") & (df_lzifu[\"WHAN\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: LINER SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"LINER\")].shape[0]\n",
    "N_agree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"LINER\") & (df_lzifu[\"WHAN\"] != \"HOLMES\") & (df_lzifu[\"WHAN\"] == \"AGN/HOLMES/shocks\")].shape[0]\n",
    "N_disagree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"LINER\") & (df_lzifu[\"WHAN\"] != \"HOLMES\") & (df_lzifu[\"WHAN\"] != \"AGN/HOLMES/shocks\")].shape[0]\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAN classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAN classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified LINER spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in [\"Unknown\", \"HOLMES\", \"SF\", \"Mixing\", \"AGN/HOLMES/shocks\", \"No N2\"]:\n",
    "    N_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"LINER\") & (df_lzifu[\"WHAN\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots: BPT, WHAN, WHAV* for each of the BPT categories\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# WHAV* - each component shown separately\n",
    "col_x = \"sigma_gas - sigma_*\"\n",
    "col_y = \"log HALPHA EW\"\n",
    "col_z = \"count\"\n",
    "\n",
    "for cat in bpt_labels:\n",
    "    df_cat = df_lzifu[df_lzifu[\"BPT (total)\"] == cat]\n",
    "    if df_cat.shape[0] == 0:\n",
    "        continue\n",
    "        \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "    fig.subplots_adjust(wspace=0)\n",
    "    bbox = axs[-1].get_position()\n",
    "    fig.add_axes([bbox.x0 + bbox.width, bbox.y0, bbox.width * 0.1, bbox.height])\n",
    "    \n",
    "    for ii in range(3):\n",
    "        if all(df_cat[f\"{col_x} (component {ii})\"].isna()) or all(df_cat[f\"{col_y} (component {ii})\"].isna()):\n",
    "            continue\n",
    "        plot2dhistcontours(df_cat, \n",
    "                           col_x=f\"{col_x} (component {ii})\", \n",
    "                           col_y=f\"{col_y} (component {ii})\",\n",
    "                           col_z=col_z, log_z=True if col_z == \"count\" else False, \n",
    "                           ax=axs[ii], nbins=100, vmin=1, vmax=1e3, contours=True, colors=\"white\", \n",
    "                           plot_colorbar=True if ii == 2 else False)\n",
    "\n",
    "    # Decorations\n",
    "    axs[1].set_title(cat)\n",
    "    [ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "    [ax.set_yticklabels([]) for ax in axs[1:]]\n",
    "\n",
    "    # Grid on\n",
    "    [ax.grid() for ax in axs]\n",
    "    \n",
    "    # Save \n",
    "    if savefigs:\n",
    "        fig.savefig(os.path.join(fig_path, f\"BPT_SAMI_indv_{cat.replace(' ', '_')}_{fname_fn(col_z)}.pdf\"), bbox_inches=\"tight\", format=\"pdf\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots: BPT, WHAN, WHAV* for each of our N2 categories\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4605773bc1d24b9e865269e3f7fae873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py:1110: RuntimeWarning: invalid value encountered in less_equal\n",
      "  mask |= resdat <= 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e551dbc568a45a4b03d3940408d7644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py:1110: RuntimeWarning: invalid value encountered in less_equal\n",
      "  mask |= resdat <= 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f465b147fb5b40cbb64b36771c8096f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/matplotlib/colors.py:1110: RuntimeWarning: invalid value encountered in less_equal\n",
      "  mask |= resdat <= 0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/priv/meggs3/u5708159/SAMI/figs/paper/BPT_SAMI_indv_AGN/HOLMES/shocks_count.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-cc891cc31583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msavefigs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"BPT_SAMI_indv_{cat.replace(' ', '_')}_{fname_fn(col_z)}.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2080\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2082\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2083\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_pdf.py\u001b[0m in \u001b[0;36mprint_pdf\u001b[0;34m(self, filename, dpi, bbox_inches_restore, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, metadata)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_file_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_opened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/priv/meggs3/u5708159/SAMI/figs/paper/BPT_SAMI_indv_AGN/HOLMES/shocks_count.pdf'"
     ]
    }
   ],
   "source": [
    "col_z = \"count\"\n",
    "\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# BPT - based on TOTAL fluxes\n",
    "for cat in [\"SF\", \"Mixing\", \"AGN/HOLMES/shocks\", \"HOLMES\"]:\n",
    "    df_cat = df[df[\"WHAN\"] == cat]\n",
    "    if df_cat.shape[0] == 0:\n",
    "        continue\n",
    "    col_y = \"log O3 (total)\"\n",
    "    fig, axs, cax = plot_empty_BPT_diagram(colorbar=True, nrows=1, include_Law2021=True)\n",
    "    \n",
    "    # Plot 2D histograms of the subset\n",
    "    plot2dhistcontours(df_cat, col_x=\"log N2 (total)\", col_y=col_y, col_z=col_z, log_z=True if col_z == \"count\" else False, vmin=1, vmax=1e3, ax=axs[0], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "    plot2dhistcontours(df_cat, col_x=\"log S2 (total)\", col_y=col_y, col_z=col_z, log_z=True if col_z == \"count\" else False, vmin=1, vmax=1e3, ax=axs[1], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "    plot2dhistcontours(df_cat, col_x=\"log O1 (total)\", col_y=col_y, col_z=col_z, log_z=True if col_z == \"count\" else False, vmin=1, vmax=1e3, ax=axs[2], nbins=100, contours=True, colors=\"white\", cax=cax, plot_colorbar=True)\n",
    "\n",
    "    # Decorations\n",
    "    axs[1].set_title(cat)\n",
    "    [ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "\n",
    "    # Grid on\n",
    "    [ax.grid() for ax in axs]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b0ce31294a49d0b8050c702bd7d173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u5708159/python/Modules/spaxelsleuth/plotting/plotgalaxies.py:178: UserWarning: No contour levels were found within the data range.\n",
      "  linewidths=linewidths)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eede61f39f74e7bb408a44bf43f5531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u5708159/python/Modules/spaxelsleuth/plotting/plotgalaxies.py:214: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  cax = fig.add_axes([bbox.x0 + bbox.width, bbox.y0, bbox.width * 0.1, bbox.height])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e77b20abee4deca69aa3fbeb221e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d032d1a9bf6544e08d1e7b4e6852b11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# WHAN - each component shown separately\n",
    "col_x = \"log N2\"\n",
    "col_y = \"log HALPHA EW\"\n",
    "col_z = \"count\"\n",
    "\n",
    "for cat in [\"HOLMES\", \"SF\", \"Mixing\", \"AGN/HOLMES/shocks\"]:\n",
    "    df_cat = df_lzifu[df_lzifu[\"WHAN\"] == cat]\n",
    "    if df_cat.shape[0] == 0:\n",
    "        continue\n",
    "        \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "    fig.subplots_adjust(wspace=0)\n",
    "    bbox = axs[-1].get_position()\n",
    "    fig.add_axes([bbox.x0 + bbox.width, bbox.y0, bbox.width * 0.1, bbox.height])\n",
    "    \n",
    "    for ii in range(3):\n",
    "        if all(df_cat[f\"{col_x} (component {ii})\"].isna()) or all(df_cat[f\"{col_y} (component {ii})\"].isna()):\n",
    "            continue\n",
    "        plot2dhistcontours(df_cat, \n",
    "                           col_x=f\"{col_x} (component {ii})\", \n",
    "                           col_y=f\"{col_y} (component {ii})\",\n",
    "                           col_z=col_z, log_z=True if col_z == \"count\" else False, \n",
    "                           ax=axs[ii], nbins=100, vmin=1, vmax=1e3, contours=True, colors=\"white\", \n",
    "                           plot_colorbar=True if ii == 2 else False)\n",
    "\n",
    "    # Decorations\n",
    "    axs[1].set_title(cat)\n",
    "    [ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "    [ax.set_yticklabels([]) for ax in axs[1:]]\n",
    "\n",
    "    # Grid on\n",
    "    [ax.grid() for ax in axs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0911e4fdc44b95b084c32388079bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# WHAV* - each component shown separately\n",
    "col_x = \"sigma_gas - sigma_*\"\n",
    "col_y = \"log HALPHA EW\"\n",
    "col_z = \"count\"\n",
    "\n",
    "# for cat in [\"HOLMES\", \"SF\", \"Mixing\", \"AGN/HOLMES/shocks\"]:\n",
    "for cat in [\"No N2\"]:\n",
    "    df_cat = df_lzifu[df_lzifu[\"WHAN\"] == cat]\n",
    "    if df_cat.shape[0] == 0:\n",
    "        continue\n",
    "        \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "    fig.subplots_adjust(wspace=0)\n",
    "    bbox = axs[-1].get_position()\n",
    "    fig.add_axes([bbox.x0 + bbox.width, bbox.y0, bbox.width * 0.1, bbox.height])\n",
    "    \n",
    "    for ii in range(3):\n",
    "        if all(df_cat[f\"{col_x} (component {ii})\"].isna()) or all(df_cat[f\"{col_y} (component {ii})\"].isna()):\n",
    "            continue\n",
    "        plot2dhistcontours(df_cat, \n",
    "                           col_x=f\"{col_x} (component {ii})\", \n",
    "                           col_y=f\"{col_y} (component {ii})\",\n",
    "                           col_z=col_z, log_z=True if col_z == \"count\" else False, \n",
    "                           ax=axs[ii], nbins=100, vmin=1, vmax=1e3, contours=True, colors=\"white\", \n",
    "                           plot_colorbar=True if ii == 2 else False)\n",
    "\n",
    "    # Decorations\n",
    "    axs[1].set_title(cat)\n",
    "    [ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "    [ax.set_yticklabels([]) for ax in axs[1:]]\n",
    "\n",
    "    # Grid on\n",
    "    [ax.grid() for ax in axs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# ///////////////////////////////////////////////////////////////////////////////\\n# SF-like spaxels\\n#///////////////////////////////////////////////////////////////////////////////\\n# Wind: number of components > 1, AND EITHER delta sigma of 1 or 2 is > 0\\n# Note: may want to also add if ncomponents == 1 but delta_sigma >> 0. \\n# How many SF (either classified via BPT or N2) spaxels are there like this, though? Just checked - only ~0.1% have dsigma > 0 by 3sigma, so probably don\\'t worry \\ncond_SF_no_wind = cond_SF & ~(df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | df_lzifu[\"Kinematically disturbed (component 2)\"])\\ndf_lzifu.loc[cond_SF_no_wind, \"WHAV*\"] = \"SF + no wind\"\\n\\ncond_SF_wind = cond_SF & (df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | df_lzifu[\"Kinematically disturbed (component 2)\"])\\ndf_lzifu.loc[cond_SF_wind, \"WHAV*\"] = \"SF + wind\"\\n\\n# SF + HOLMES \\ncond_SF_no_wind_HOLMES = cond_SF_no_wind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\\ndf_lzifu.loc[cond_SF_no_wind_HOLMES, \"WHAV*\"] = \"SF + HOLMES + no wind\"\\n\\ncond_SF_wind_HOLMES = cond_SF_wind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\\ndf_lzifu.loc[cond_SF_wind_HOLMES, \"WHAV*\"] = \"SF + HOLMES + wind\"\\n\\n\\n# Note: what to do about low-metallicity AGN? e.g., ones that are classified as ambiguous that have log N2 < -0.35 so get lumped in with SF?\\n\\n#///////////////////////////////////////////////////////////////////////////////\\n# Mixing-like spaxels\\n#///////////////////////////////////////////////////////////////////////////////\\n# wind/no wind\\n# Note: <1% of composite/mixing-like spaxels have ncomponents == 1 but delta_sigma >> 0 by 3sigma\\ncond_Mixing_no_wind = cond_Mixing & ~(df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | df_lzifu[\"Kinematically disturbed (component 2)\"])\\ndf_lzifu.loc[cond_Mixing_no_wind, \"WHAV*\"] = \"Mixing + no wind\"\\n\\ncond_Mixing_wind = cond_Mixing & (df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | df_lzifu[\"Kinematically disturbed (component 2)\"])\\ndf_lzifu.loc[cond_Mixing_wind, \"WHAV*\"] = \"Mixing + wind\"\\n\\n# Mixing + HOLMES \\ncond_Mixing_no_wind_HOLMES = cond_Mixing_no_wind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\\ndf_lzifu.loc[cond_Mixing_no_wind_HOLMES, \"WHAV*\"] = \"Mixing + HOLMES + no wind\"\\n\\n# Mixing + HOLMES + wind\\ncond_Mixing_wind_HOLMES = cond_Mixing_wind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\\ndf_lzifu.loc[cond_Mixing_wind_HOLMES, \"WHAV*\"] = \"Mixing + HOLMES + wind\"\\n\\n#///////////////////////////////////////////////////////////////////////////////\\n# AGN-like spaxels\\n#///////////////////////////////////////////////////////////////////////////////\\n# If there is 1 component and its EW is > 0, then it\\'s an AGN. Note that Seyfert-like components have a range of EWs, so we can\\'t really split between LLAGN and Seyferts here - really need [OIII] for that.\\ncond_AGN_no_wind = cond_AGN & (df_lzifu[\"Number of components\"] == 1) & (df_lzifu[\"HALPHA EW (component 0)\"] > 3) & ~df_lzifu[\"Kinematically disturbed (component 0)\"]\\ndf_lzifu.loc[cond_AGN_no_wind, \"WHAV*\"] = \"AGN only\"\\n\\n# AGN + wind\\ncond_AGN_nowind = cond_AGN & ~(df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | (df_lzifu[\"Kinematically disturbed (component 2)\"] ))\\ndf_lzifu.loc[cond_AGN_nowind, \"WHAV*\"] = \"AGN + no wind\"\\n\\ncond_AGN_wind = cond_AGN & (df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | (df_lzifu[\"Kinematically disturbed (component 2)\"] ))\\ndf_lzifu.loc[cond_AGN_wind, \"WHAV*\"] = \"AGN + wind\"\\n\\n# If there are multiple components and at least one of them is in the HOLMES regime, then classify it as HOLMES + AGN. \\ncond_AGN_nowind_HOLMES = cond_AGN_nowind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\\ndf_lzifu.loc[cond_AGN_nowind_HOLMES, \"WHAV*\"] = \"AGN + HOLMES + no wind\"\\n\\ncond_AGN_wind_HOLMES = cond_AGN_wind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\\ndf_lzifu.loc[cond_AGN_wind_HOLMES, \"WHAV*\"] = \"AGN + HOLMES + wind\"\\n\\n#///////////////////////////////////////////////////////////////////////////////\\n# Numerical labels\\n#///////////////////////////////////////////////////////////////////////////////\\nnum_dict = {\\n    \"Unknown\": -1,\\n    \"HOLMES\": 0,\\n    \"Mixing + HOLMES + no wind\": 1,\\n    \"Mixing + HOLMES + wind\": 2,\\n    \"Mixing + no wind\": 3,\\n    \"Mixing + wind\": 4,    \\n    \"AGN + HOLMES + no wind\": 5,\\n    \"AGN + HOLMES + wind\": 6,\\n    \"AGN + no wind\": 7,\\n    \"AGN + wind\": 8,\\n    \"SF + HOLMES + no wind\": 9,\\n    \"SF + HOLMES + wind\": 10,\\n    \"SF + no wind\": 11,\\n    \"SF + wind\": 12\\n}\\ncats = list(num_dict.keys())\\nfor cat in cats:\\n    df_lzifu.loc[df_lzifu[\"WHAV*\"] == cat, \"WHAV* (numeric)\"] = num_dict[cat]\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ///////////////////////////////////////////////////////////////////////////////\n",
    "# SF-like spaxels\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# Wind: number of components > 1, AND EITHER delta sigma of 1 or 2 is > 0\n",
    "# Note: may want to also add if ncomponents == 1 but delta_sigma >> 0. \n",
    "# How many SF (either classified via BPT or N2) spaxels are there like this, though? Just checked - only ~0.1% have dsigma > 0 by 3sigma, so probably don't worry \n",
    "cond_SF_no_wind = cond_SF & ~(df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | df_lzifu[\"Kinematically disturbed (component 2)\"])\n",
    "df_lzifu.loc[cond_SF_no_wind, \"WHAV*\"] = \"SF + no wind\"\n",
    "\n",
    "cond_SF_wind = cond_SF & (df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | df_lzifu[\"Kinematically disturbed (component 2)\"])\n",
    "df_lzifu.loc[cond_SF_wind, \"WHAV*\"] = \"SF + wind\"\n",
    "\n",
    "# SF + HOLMES \n",
    "cond_SF_no_wind_HOLMES = cond_SF_no_wind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\n",
    "df_lzifu.loc[cond_SF_no_wind_HOLMES, \"WHAV*\"] = \"SF + HOLMES + no wind\"\n",
    "\n",
    "cond_SF_wind_HOLMES = cond_SF_wind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\n",
    "df_lzifu.loc[cond_SF_wind_HOLMES, \"WHAV*\"] = \"SF + HOLMES + wind\"\n",
    "\n",
    "\n",
    "# Note: what to do about low-metallicity AGN? e.g., ones that are classified as ambiguous that have log N2 < -0.35 so get lumped in with SF?\n",
    "\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# Mixing-like spaxels\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# wind/no wind\n",
    "# Note: <1% of composite/mixing-like spaxels have ncomponents == 1 but delta_sigma >> 0 by 3sigma\n",
    "cond_Mixing_no_wind = cond_Mixing & ~(df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | df_lzifu[\"Kinematically disturbed (component 2)\"])\n",
    "df_lzifu.loc[cond_Mixing_no_wind, \"WHAV*\"] = \"Mixing + no wind\"\n",
    "\n",
    "cond_Mixing_wind = cond_Mixing & (df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | df_lzifu[\"Kinematically disturbed (component 2)\"])\n",
    "df_lzifu.loc[cond_Mixing_wind, \"WHAV*\"] = \"Mixing + wind\"\n",
    "\n",
    "# Mixing + HOLMES \n",
    "cond_Mixing_no_wind_HOLMES = cond_Mixing_no_wind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\n",
    "df_lzifu.loc[cond_Mixing_no_wind_HOLMES, \"WHAV*\"] = \"Mixing + HOLMES + no wind\"\n",
    "\n",
    "# Mixing + HOLMES + wind\n",
    "cond_Mixing_wind_HOLMES = cond_Mixing_wind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\n",
    "df_lzifu.loc[cond_Mixing_wind_HOLMES, \"WHAV*\"] = \"Mixing + HOLMES + wind\"\n",
    "\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# AGN-like spaxels\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# If there is 1 component and its EW is > 0, then it's an AGN. Note that Seyfert-like components have a range of EWs, so we can't really split between LLAGN and Seyferts here - really need [OIII] for that.\n",
    "cond_AGN_no_wind = cond_AGN & (df_lzifu[\"Number of components\"] == 1) & (df_lzifu[\"HALPHA EW (component 0)\"] > 3) & ~df_lzifu[\"Kinematically disturbed (component 0)\"]\n",
    "df_lzifu.loc[cond_AGN_no_wind, \"WHAV*\"] = \"AGN only\"\n",
    "\n",
    "# AGN + wind\n",
    "cond_AGN_nowind = cond_AGN & ~(df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | (df_lzifu[\"Kinematically disturbed (component 2)\"] ))\n",
    "df_lzifu.loc[cond_AGN_nowind, \"WHAV*\"] = \"AGN + no wind\"\n",
    "\n",
    "cond_AGN_wind = cond_AGN & (df_lzifu[\"Kinematically disturbed (component 0)\"] | df_lzifu[\"Kinematically disturbed (component 1)\"] | (df_lzifu[\"Kinematically disturbed (component 2)\"] ))\n",
    "df_lzifu.loc[cond_AGN_wind, \"WHAV*\"] = \"AGN + wind\"\n",
    "\n",
    "# If there are multiple components and at least one of them is in the HOLMES regime, then classify it as HOLMES + AGN. \n",
    "cond_AGN_nowind_HOLMES = cond_AGN_nowind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\n",
    "df_lzifu.loc[cond_AGN_nowind_HOLMES, \"WHAV*\"] = \"AGN + HOLMES + no wind\"\n",
    "\n",
    "cond_AGN_wind_HOLMES = cond_AGN_wind & (df_lzifu[\"Number of components\"] >= 2) & (df_lzifu[\"Possible HOLMES (component 0)\"] | df_lzifu[\"Possible HOLMES (component 1)\"] | df_lzifu[\"Possible HOLMES (component 2)\"])\n",
    "df_lzifu.loc[cond_AGN_wind_HOLMES, \"WHAV*\"] = \"AGN + HOLMES + wind\"\n",
    "\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# Numerical labels\n",
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "num_dict = {\n",
    "    \"Unknown\": -1,\n",
    "    \"HOLMES\": 0,\n",
    "    \"Mixing + HOLMES + no wind\": 1,\n",
    "    \"Mixing + HOLMES + wind\": 2,\n",
    "    \"Mixing + no wind\": 3,\n",
    "    \"Mixing + wind\": 4,    \n",
    "    \"AGN + HOLMES + no wind\": 5,\n",
    "    \"AGN + HOLMES + wind\": 6,\n",
    "    \"AGN + no wind\": 7,\n",
    "    \"AGN + wind\": 8,\n",
    "    \"SF + HOLMES + no wind\": 9,\n",
    "    \"SF + HOLMES + wind\": 10,\n",
    "    \"SF + no wind\": 11,\n",
    "    \"SF + wind\": 12\n",
    "}\n",
    "cats = list(num_dict.keys())\n",
    "for cat in cats:\n",
    "    df_lzifu.loc[df_lzifu[\"WHAV*\"] == cat, \"WHAV* (numeric)\"] = num_dict[cat]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do our classifications match up with BPT classifcations?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         & SF             & Composite      & Seyfert        & LINER          & Ambiguous      & Not classified \\\\\n",
      "SF + wind                \t&      10.73\\%\t&       1.80\\%\t&       0.09\\%\t&       0.00\\%\t&       4.27\\%\t&       0.26\\%\\\\\n",
      "SF + no wind             \t&      83.39\\%\t&      19.29\\%\t&       1.69\\%\t&       0.00\\%\t&      66.51\\%\t&       4.66\\%\\\\\n",
      "SF + HOLMES + wind       \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\\\\\n",
      "SF + HOLMES + no wind    \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\\\\\n",
      "AGN + wind               \t&       0.00\\%\t&       2.47\\%\t&      43.93\\%\t&       3.20\\%\t&       2.79\\%\t&       0.17\\%\\\\\n",
      "AGN + no wind            \t&       0.01\\%\t&       7.28\\%\t&      19.19\\%\t&      20.88\\%\t&       6.71\\%\t&       1.49\\%\\\\\n",
      "AGN + HOLMES + wind      \t&       0.00\\%\t&       0.09\\%\t&       2.07\\%\t&       1.43\\%\t&       0.12\\%\t&       0.04\\%\\\\\n",
      "AGN + HOLMES + no wind   \t&       0.00\\%\t&       0.28\\%\t&       1.13\\%\t&       1.70\\%\t&       0.38\\%\t&       0.04\\%\\\\\n",
      "Mixing + wind            \t&       0.56\\%\t&       8.09\\%\t&       4.52\\%\t&       0.07\\%\t&       0.93\\%\t&       0.22\\%\\\\\n",
      "Mixing + no wind         \t&       5.28\\%\t&      57.48\\%\t&       0.94\\%\t&       0.14\\%\t&       7.75\\%\t&       3.69\\%\\\\\n",
      "Mixing + HOLMES + wind   \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\\\\\n",
      "Mixing + HOLMES + no wind\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\\\\\n",
      "HOLMES                   \t&       0.03\\%\t&       3.21\\%\t&      26.43\\%\t&      72.59\\%\t&      10.54\\%\t&       5.58\\%\\\\\n",
      "Unknown                  \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&      83.84\\%\\\\\n",
      "Total                    &           27339 &            7404 &            1063 &            1470 &            3443 &          463155 \\\\\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################################\n",
    "# Table: comparison between BPT- and N2- and \\ewha{}-based spectral categories for the LZIFU high-SN subset.\n",
    "#############################################################################################################\n",
    "whav_cats = list(reversed(whav_labels))\n",
    "s = f\"{'':25s}\"\n",
    "s_tot = f\"{'Total':25s}\"\n",
    "for bpt in [\"SF\", \"Composite\", \"Seyfert\", \"LINER\", \"Ambiguous\", \"Not classified\"]:\n",
    "    s += f\"& {bpt:15s}\"\n",
    "    N_bpt_tot = df_lzifu[(df_lzifu[\"BPT (total)\"] == bpt)].shape[0]\n",
    "    s_tot += f\"& {N_bpt_tot:15d} \"\n",
    "s += \"\\\\\\\\\"\n",
    "s_tot += \"\\\\\\\\\"\n",
    "print(s)\n",
    "for whav_cat in whav_cats:\n",
    "    s = f\"{whav_cat:25s}\"\n",
    "    for bpt in [\"SF\", \"Composite\", \"Seyfert\", \"LINER\", \"Ambiguous\", \"Not classified\"]:\n",
    "        N_bpt_tot =         df_lzifu[(df_lzifu[\"BPT (total)\"] == bpt)].shape[0]\n",
    "        N_bpt_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == bpt) & (df_lzifu[\"WHAV*\"] == whav_cat)].shape[0]\n",
    "        s += f\"\\t& {N_bpt_in_this_cat / N_bpt_tot * 100:10.2f}\\%\"\n",
    "    s += \"\\\\\\\\\"\n",
    "    print(s)\n",
    "print(s_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         & SF             & Composite      & Seyfert        & LINER          & Ambiguous      & Not classified \\\\\n",
      "SF + wind                \t&       2.69\\%\t&       0.63\\%\t&       1.88\\%\t&       0.00\\%\t&       0.58\\%\t&       0.01\\%\\\\\n",
      "SF + no wind             \t&      94.27\\%\t&      14.72\\%\t&       5.34\\%\t&       0.01\\%\t&      79.04\\%\t&       7.46\\%\\\\\n",
      "SF + HOLMES + wind       \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\\\\\n",
      "SF + HOLMES + no wind    \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\\\\\n",
      "AGN + wind               \t&       0.00\\%\t&       2.23\\%\t&      27.80\\%\t&       4.57\\%\t&       1.08\\%\t&       0.04\\%\\\\\n",
      "AGN + no wind            \t&       0.00\\%\t&       8.39\\%\t&      23.74\\%\t&      12.40\\%\t&       3.99\\%\t&       1.62\\%\\\\\n",
      "AGN + HOLMES + wind      \t&       0.00\\%\t&       0.38\\%\t&       3.73\\%\t&       2.34\\%\t&       0.19\\%\t&       0.01\\%\\\\\n",
      "AGN + HOLMES + no wind   \t&       0.00\\%\t&       0.97\\%\t&       1.61\\%\t&       2.04\\%\t&       0.38\\%\t&       0.01\\%\\\\\n",
      "Mixing + wind            \t&       0.26\\%\t&       5.49\\%\t&       6.62\\%\t&       0.54\\%\t&       0.68\\%\t&       0.02\\%\\\\\n",
      "Mixing + no wind         \t&       2.76\\%\t&      60.80\\%\t&       9.36\\%\t&       0.74\\%\t&       5.24\\%\t&       3.59\\%\\\\\n",
      "Mixing + HOLMES + wind   \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\\\\\n",
      "Mixing + HOLMES + no wind\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\\\\\n",
      "HOLMES                   \t&       0.02\\%\t&       6.39\\%\t&      19.92\\%\t&      77.35\\%\t&       8.82\\%\t&       6.38\\%\\\\\n",
      "Unknown                  \t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&       0.00\\%\t&      80.87\\%\\\\\n",
      "Total                    &          301858 &           35284 &            3353 &            8919 &           31054 &         1459687 \\\\\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################################\n",
    "# Table: comparison between BPT- and N2- and \\ewha{}-based spectral categories for the entire SAMI sample.\n",
    "#############################################################################################################\n",
    "whav_cats = list(reversed(whav_labels))\n",
    "s = f\"{'':25s}\"\n",
    "s_tot = f\"{'Total':25s}\"\n",
    "for bpt in [\"SF\", \"Composite\", \"Seyfert\", \"LINER\", \"Ambiguous\", \"Not classified\"]:\n",
    "    s += f\"& {bpt:15s}\"\n",
    "    N_bpt_tot = df[(df[\"BPT (total)\"] == bpt)].shape[0]\n",
    "    s_tot += f\"& {N_bpt_tot:15d} \"\n",
    "s += \"\\\\\\\\\"\n",
    "s_tot += \"\\\\\\\\\"\n",
    "print(s)\n",
    "for whav_cat in whav_cats:\n",
    "    s = f\"{whav_cat:25s}\"\n",
    "    for bpt in [\"SF\", \"Composite\", \"Seyfert\", \"LINER\", \"Ambiguous\", \"Not classified\"]:\n",
    "        N_bpt_tot =         df[(df[\"BPT (total)\"] == bpt)].shape[0]\n",
    "        N_bpt_in_this_cat = df[(df[\"BPT (total)\"] == bpt) & (df[\"WHAV*\"] == whav_cat)].shape[0]\n",
    "        s += f\"\\t& {N_bpt_in_this_cat / N_bpt_tot * 100:10.2f}\\%\"\n",
    "    s += \"\\\\\\\\\"\n",
    "    print(s)\n",
    "print(s_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################################################\n",
      "LZIFU SUBSET: STAR-FORMING SPAXELS\n",
      "############################################################################################\n",
      "Fraction of BPT-classified SF spaxels with a WHAV* classification that agrees: 25733/27339 = 94.13%\n",
      "Fraction of BPT-classified SF spaxels with a WHAV* classification that disagrees: 1606/27339 = 5.87%\n",
      "--------------------------------------------------------------------------------------------\n",
      "Of all BPT-classified SF spaxels:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0fcd5c6a3af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Of all BPT-classified SF spaxels:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mN_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mN_in_this_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_lzifu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_lzifu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BPT (total)\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SF\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_lzifu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"WHAV*\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cats' is not defined"
     ]
    }
   ],
   "source": [
    "# What % of all BPT-classified SF spaxels are in a WHAV* category that includes SF?\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: STAR-FORMING SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"SF\")].shape[0]\n",
    "N_agree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"SF\") & (df_lzifu[\"WHAV*\"].isin([\"SF + no wind\", \"SF + wind\", \"SF + HOLMES + wind\", \"SF + HOLMES + no wind\"]))].shape[0]\n",
    "N_disagree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"SF\") & ~(df_lzifu[\"WHAV*\"].isin([\"SF + no wind\", \"SF + wind\", \"SF + HOLMES + wind\", \"SF + HOLMES + no wind\"]))].shape[0]\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAV* classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAV* classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified SF spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"SF\") & (df_lzifu[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "# Composite/mixng?\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: COMPOSITE SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "\n",
    "N_BPT = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Composite\")].shape[0]\n",
    "N_agree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Composite\") & (df_lzifu[\"WHAV*\"].isin([\"Mixing + no wind\", \"Mixing + wind\", \"Mixing + HOLMES + wind\", \"Mixing + HOLMES + no wind\"]))].shape[0]\n",
    "N_disagree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Composite\") & ~(df_lzifu[\"WHAV*\"].isin([\"Mixing + no wind\", \"Mixing + wind\", \"Mixing + HOLMES + wind\", \"Mixing + HOLMES + no wind\"]))].shape[0]\n",
    "print(f\"Fraction of BPT-classified composite spaxels with a WHAV* classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified composite spaxels with a WHAV* classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified Composite spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Composite\") & (df_lzifu[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "# Seyferts\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: SEYFERT SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Seyfert\")].shape[0]  \n",
    "N_agree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Seyfert\") & (df_lzifu[\"WHAV*\"].isin([\"AGN + no wind\", \"AGN + wind\", \"AGN + HOLMES + wind\", \"AGN + HOLMES + no wind\"]))].shape[0]\n",
    "N_disagree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Seyfert\") & ~(df_lzifu[\"WHAV*\"].isin([\"AGN + no wind\", \"AGN + wind\", \"AGN + HOLMES + wind\", \"AGN + HOLMES + no wind\"]))].shape[0]\n",
    "print(f\"Fraction of BPT-classified Seyfert spaxels with a WHAV* classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified Seyfert spaxels with a WHAV* classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified Seyfert spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Seyfert\") & (df_lzifu[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "# LINERs\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: LINER SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"LINER\")].shape[0]  \n",
    "N_agree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"LINER\") & (df_lzifu[\"WHAV*\"].isin([\"HOLMES\", \"AGN + no wind\", \"AGN + wind\", \"AGN + HOLMES + wind\", \"AGN + HOLMES + no wind\"]))].shape[0]\n",
    "N_disagree = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"LINER\") & ~(df_lzifu[\"WHAV*\"].isin([\"HOLMES\", \"AGN + no wind\", \"AGN + wind\", \"AGN + HOLMES + wind\", \"AGN + HOLMES + no wind\"]))].shape[0]\n",
    "print(f\"Fraction of BPT-classified LINER spaxels with a WHAV* classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified LINER spaxels with a WHAV* classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified LINER spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"LINER\") & (df_lzifu[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "    \n",
    "# Ambiguous\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: AMBIGUOUS SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Ambiguous\")].shape[0]  \n",
    "print(\"Of all BPT-classified Ambiguous spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Ambiguous\") & (df_lzifu[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "# NOT CLASSIFIED\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: NOT CLASSIFIED SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Not classified\")].shape[0]  \n",
    "print(\"Of all BPT-classified Not classified spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df_lzifu[(df_lzifu[\"BPT (total)\"] == \"Not classified\") & (df_lzifu[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "    \n",
    "# Finally: how many spaxels do have Halpha but don't have an N2 measurement?\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"LZIFU SUBSET: SPAXELS WITH NO N2\")\n",
    "print(\"############################################################################################\")\n",
    "N_tot = df_lzifu[~np.isnan(df_lzifu[\"HALPHA EW (component 0)\"]) & ~np.isnan(df_lzifu[\"sigma_gas - sigma_* (component 0)\"])].shape[0]\n",
    "N_no_N2 = df_lzifu[(df_lzifu[\"WHAV*\"] == \"No N2\") & (~np.isnan(df_lzifu[\"HALPHA EW (component 0)\"]) & ~np.isnan(df_lzifu[\"sigma_gas - sigma_* (component 0)\"]))].shape[0]\n",
    "print(f\"{N_no_N2:4d}/{N_tot:4d} = {N_no_N2 / N_tot * 100:3.2f}% of spaxels with EW and delta_sigma measurements have no N2 measurement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What % of all BPT-classified SF spaxels are in a WHAV* category that includes SF?\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"ENTIRE SAMI SAMPLE: STAR-FORMING SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df[(df[\"BPT (total)\"] == \"SF\")].shape[0]\n",
    "N_agree = df[(df[\"BPT (total)\"] == \"SF\") & (df[\"WHAV*\"].isin([\"SF + no wind\", \"SF + wind\", \"SF + HOLMES + wind\", \"SF + HOLMES + no wind\"]))].shape[0]\n",
    "N_disagree = df[(df[\"BPT (total)\"] == \"SF\") & ~(df[\"WHAV*\"].isin([\"SF + no wind\", \"SF + wind\", \"SF + HOLMES + wind\", \"SF + HOLMES + no wind\"]))].shape[0]\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAV* classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified SF spaxels with a WHAV* classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified SF spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df[(df[\"BPT (total)\"] == \"SF\") & (df[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "# Composite/mixng?\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"ENTIRE SAMI SAMPLE: COMPOSITE SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "\n",
    "N_BPT = df[(df[\"BPT (total)\"] == \"Composite\")].shape[0]\n",
    "N_agree = df[(df[\"BPT (total)\"] == \"Composite\") & (df[\"WHAV*\"].isin([\"Mixing + no wind\", \"Mixing + wind\", \"Mixing + HOLMES + wind\", \"Mixing + HOLMES + no wind\"]))].shape[0]\n",
    "N_disagree = df[(df[\"BPT (total)\"] == \"Composite\") & ~(df[\"WHAV*\"].isin([\"Mixing + no wind\", \"Mixing + wind\", \"Mixing + HOLMES + wind\", \"Mixing + HOLMES + no wind\"]))].shape[0]\n",
    "print(f\"Fraction of BPT-classified composite spaxels with a WHAV* classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified composite spaxels with a WHAV* classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified Composite spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df[(df[\"BPT (total)\"] == \"Composite\") & (df[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "# Seyferts\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"ENTIRE SAMI SAMPLE: SEYFERT SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df[(df[\"BPT (total)\"] == \"Seyfert\")].shape[0]  \n",
    "N_agree = df[(df[\"BPT (total)\"] == \"Seyfert\") & (df[\"WHAV*\"].isin([\"AGN + no wind\", \"AGN + wind\", \"AGN + HOLMES + wind\", \"AGN + HOLMES + no wind\"]))].shape[0]\n",
    "N_disagree = df[(df[\"BPT (total)\"] == \"Seyfert\") & ~(df[\"WHAV*\"].isin([\"AGN + no wind\", \"AGN + wind\", \"AGN + HOLMES + wind\", \"AGN + HOLMES + no wind\"]))].shape[0]\n",
    "print(f\"Fraction of BPT-classified Seyfert spaxels with a WHAV* classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified Seyfert spaxels with a WHAV* classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified Seyfert spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df[(df[\"BPT (total)\"] == \"Seyfert\") & (df[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "# LINERs\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"ENTIRE SAMI SAMPLE: LINER SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df[(df[\"BPT (total)\"] == \"LINER\")].shape[0]  \n",
    "N_agree = df[(df[\"BPT (total)\"] == \"LINER\") & (df[\"WHAV*\"].isin([\"HOLMES\", \"AGN + no wind\", \"AGN + wind\", \"AGN + HOLMES + wind\", \"AGN + HOLMES + no wind\"]))].shape[0]\n",
    "N_disagree = df[(df[\"BPT (total)\"] == \"LINER\") & ~(df[\"WHAV*\"].isin([\"HOLMES\", \"AGN + no wind\", \"AGN + wind\", \"AGN + HOLMES + wind\", \"AGN + HOLMES + no wind\"]))].shape[0]\n",
    "print(f\"Fraction of BPT-classified LINER spaxels with a WHAV* classification that agrees: {N_agree}/{N_BPT} = {N_agree / N_BPT * 100:.2f}%\")\n",
    "print(f\"Fraction of BPT-classified LINER spaxels with a WHAV* classification that disagrees: {N_disagree}/{N_BPT} = {N_disagree / N_BPT * 100:.2f}%\")\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(\"Of all BPT-classified LINER spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df[(df[\"BPT (total)\"] == \"LINER\") & (df[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "    \n",
    "# Ambiguous\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"ENTIRE SAMI SAMPLE: AMBIGUOUS SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df[(df[\"BPT (total)\"] == \"Ambiguous\")].shape[0]  \n",
    "print(\"Of all BPT-classified Ambiguous spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df[(df[\"BPT (total)\"] == \"Ambiguous\") & (df[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "\n",
    "# NOT CLASSIFIED\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"ENTIRE SAMI SAMPLE: NOT CLASSIFIED SPAXELS\")\n",
    "print(\"############################################################################################\")\n",
    "N_BPT = df[(df[\"BPT (total)\"] == \"Not classified\")].shape[0]  \n",
    "print(\"Of all BPT-classified Not classified spaxels:\")\n",
    "N_tot = 0\n",
    "for cat in cats:\n",
    "    N_in_this_cat = df[(df[\"BPT (total)\"] == \"Not classified\") & (df[\"WHAV*\"] == cat)].shape[0]\n",
    "    print(f\"\\t{N_in_this_cat:4d}/{N_BPT:4d} = {N_in_this_cat / N_BPT * 100:3.2f}% are in category '{cat}'\")\n",
    "    N_tot += N_in_this_cat\n",
    "    \n",
    "# Finally: how many spaxels do have Halpha but don't have an N2 measurement?\n",
    "print(\"\\n############################################################################################\")\n",
    "print(\"ENTIRE SAMI SAMPLE: SPAXELS WITH NO N2\")\n",
    "print(\"############################################################################################\")\n",
    "N_tot = df[~np.isnan(df[\"HALPHA EW (component 0)\"]) & ~np.isnan(df[\"sigma_gas - sigma_* (component 0)\"])].shape[0]\n",
    "N_no_N2 = df[(df[\"WHAV*\"] == \"No N2\") & (~np.isnan(df[\"HALPHA EW (component 0)\"]) & ~np.isnan(df[\"sigma_gas - sigma_* (component 0)\"]))].shape[0]\n",
    "print(f\"{N_no_N2:4d}/{N_tot:4d} = {N_no_N2 / N_tot * 100:3.2f}% of spaxels with EW and delta_sigma measurements have no N2 measurement\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPT, WHAN, WHAV* diagrams to compare classifications\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# BPT (based on total fluxes): all categories\n",
    "col_z = \"WHAV* (numeric)\"\n",
    "fig, axs, cax = plot_empty_BPT_diagram(colorbar=True, nrows=1, include_Law2021=True)\n",
    "\n",
    "# Plot 2D histograms of the subset\n",
    "plot2dhistcontours(df, col_x=\"log N2 (total)\", col_y=\"log O3 (total)\", col_z=col_z, log_z=True if col_z == \"count\" else False, ax=axs[0], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "plot2dhistcontours(df, col_x=\"log S2 (total)\", col_y=\"log O3 (total)\", col_z=col_z, log_z=True if col_z == \"count\" else False, ax=axs[1], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "plot2dhistcontours(df, col_x=\"log O1 (total)\", col_y=\"log O3 (total)\", col_z=col_z, log_z=True if col_z == \"count\" else False, ax=axs[2], nbins=100, contours=True, colors=\"white\", cax=cax, plot_colorbar=True)\n",
    "\n",
    "# Decorations\n",
    "# axs[1].set_title(cat)\n",
    "[ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "\n",
    "# Grid on\n",
    "[ax.grid() for ax in axs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# BPT (based on total fluxes): each category shown separately\n",
    "col_z = \"WHAV* (numeric)\"\n",
    "for cat in df_lzifu[\"WHAV*\"].unique()[1:2]:\n",
    "    df_cat = df_lzifu[df_lzifu[\"WHAV*\"] == cat]\n",
    "    if df_cat.shape[0] == 0:\n",
    "        continue\n",
    "    fig, axs, cax = plot_empty_BPT_diagram(colorbar=True, nrows=1, include_Law2021=True)\n",
    "\n",
    "    # Plot 2D histograms of the subset\n",
    "    plot2dhistcontours(df_cat, col_x=\"log N2 (total)\", col_y=\"log O3 (total)\", col_z=col_z, log_z=True if col_z == \"count\" else False, ax=axs[0], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "    plot2dhistcontours(df_cat, col_x=\"log S2 (total)\", col_y=\"log O3 (total)\", col_z=col_z, log_z=True if col_z == \"count\" else False, ax=axs[1], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "    plot2dhistcontours(df_cat, col_x=\"log O1 (total)\", col_y=\"log O3 (total)\", col_z=col_z, log_z=True if col_z == \"count\" else False, ax=axs[2], nbins=100, contours=True, colors=\"white\", cax=cax, plot_colorbar=True)\n",
    "\n",
    "    # Decorations\n",
    "    axs[1].set_title(cat)\n",
    "    [ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "\n",
    "    # Grid on\n",
    "    [ax.grid() for ax in axs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# WHAN: all categories at once \n",
    "col_x = \"log N2\"\n",
    "col_y = \"log HALPHA EW\"\n",
    "col_z = \"WHAV* (numeric)\"\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "bbox = axs[-1].get_position()\n",
    "fig.add_axes([bbox.x0 + bbox.width, bbox.y0, bbox.width * 0.1, bbox.height])\n",
    "\n",
    "for ii in range(3):\n",
    "    if all(df_cat[f\"{col_x} (component {ii})\"].isna()) or all(df_cat[f\"{col_y} (component {ii})\"].isna()):\n",
    "        continue\n",
    "    plot2dhistcontours(df_lzifu, \n",
    "                       col_x=f\"{col_x} (component {ii})\", \n",
    "                       col_y=f\"{col_y} (component {ii})\",\n",
    "                       col_z=col_z, log_z=True if col_z == \"count\" else False, \n",
    "                       ax=axs[ii], nbins=100, contours=True, colors=\"white\", \n",
    "                       plot_colorbar=True if ii == 2 else False)\n",
    "\n",
    "# Decorations\n",
    "[ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "[ax.set_yticklabels([]) for ax in axs[1:]]\n",
    "\n",
    "# Grid on\n",
    "[ax.grid() for ax in axs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# WHAN: each category separately\n",
    "col_x = \"log N2\"\n",
    "col_y = \"log HALPHA EW\"\n",
    "col_z = \"WHAV* (numeric)\"\n",
    "\n",
    "for cat in df_lzifu[\"WHAV*\"].unique()[1:]:\n",
    "    df_cat = df_lzifu[df_lzifu[\"WHAV*\"] == cat]\n",
    "    if df_cat.shape[0] == 0:\n",
    "        continue\n",
    "        \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "    fig.subplots_adjust(wspace=0)\n",
    "    bbox = axs[-1].get_position()\n",
    "    fig.add_axes([bbox.x0 + bbox.width, bbox.y0, bbox.width * 0.1, bbox.height])\n",
    "    \n",
    "    for ii in range(3):\n",
    "        if all(df_cat[f\"{col_x} (component {ii})\"].isna()) or all(df_cat[f\"{col_y} (component {ii})\"].isna()):\n",
    "            continue\n",
    "        plot2dhistcontours(df_cat, \n",
    "                           col_x=f\"{col_x} (component {ii})\", \n",
    "                           col_y=f\"{col_y} (component {ii})\",\n",
    "                           col_z=col_z, log_z=True if col_z == \"count\" else False, \n",
    "                           ax=axs[ii], nbins=100, contours=True, colors=\"white\", \n",
    "                           plot_colorbar=True if ii == 2 else False)\n",
    "\n",
    "    # Decorations\n",
    "    axs[1].set_title(cat)\n",
    "    [ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "    [ax.set_yticklabels([]) for ax in axs[1:]]\n",
    "\n",
    "    # Grid on\n",
    "    [ax.grid() for ax in axs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lzifu[df_lzifu[\"WHAV*\"] == \"SF + no wind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# WHAV*: all categories at once \n",
    "col_x = \"sigma_gas - sigma_*\"\n",
    "col_y = \"log HALPHA EW\"\n",
    "col_z = \"WHAV* (numeric)\"\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "bbox = axs[-1].get_position()\n",
    "fig.add_axes([bbox.x0 + bbox.width, bbox.y0, bbox.width * 0.1, bbox.height])\n",
    "\n",
    "for ii in range(3):\n",
    "    plot2dhistcontours(df_lzifu, \n",
    "                       col_x=f\"{col_x} (component {ii})\", \n",
    "                       col_y=f\"{col_y} (component {ii})\",\n",
    "                       col_z=col_z, log_z=True if col_z == \"count\" else False, \n",
    "                       ax=axs[ii], nbins=100, contours=True, colors=\"white\", \n",
    "                       plot_colorbar=True if ii == 2 else False)\n",
    "\n",
    "# Decorations\n",
    "[ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "[ax.set_yticklabels([]) for ax in axs[1:]]\n",
    "\n",
    "# Grid on\n",
    "[ax.grid() for ax in axs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#///////////////////////////////////////////////////////////////////////////////\n",
    "# WHAV*: each category shown separately\n",
    "col_x = \"sigma_gas - sigma_*\"\n",
    "col_y = \"log HALPHA EW\"\n",
    "col_z = \"WHAV* (numeric)\"\n",
    "\n",
    "for cat in df_lzifu[\"WHAV*\"].unique()[1:]:\n",
    "    df_cat = df_lzifu[df_lzifu[\"WHAV*\"] == cat]\n",
    "    if df_cat.shape[0] == 0:\n",
    "        continue\n",
    "        \n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "    fig.subplots_adjust(wspace=0)\n",
    "    bbox = axs[-1].get_position()\n",
    "    fig.add_axes([bbox.x0 + bbox.width, bbox.y0, bbox.width * 0.1, bbox.height])\n",
    "    \n",
    "    for ii in range(3):\n",
    "        if all(df_cat[f\"{col_x} (component {ii})\"].isna()) or all(df_cat[f\"{col_y} (component {ii})\"].isna()):\n",
    "            continue\n",
    "        plot2dhistcontours(df_cat, \n",
    "                           col_x=f\"{col_x} (component {ii})\", \n",
    "                           col_y=f\"{col_y} (component {ii})\",\n",
    "                           col_z=col_z, log_z=True if col_z == \"count\" else False, \n",
    "                           ax=axs[ii], nbins=100, contours=True, colors=\"white\", \n",
    "                           plot_colorbar=True if ii == 2 else False)\n",
    "\n",
    "    # Decorations\n",
    "    axs[1].set_title(cat)\n",
    "    [ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "    [ax.set_yticklabels([]) for ax in axs[1:]]\n",
    "\n",
    "    # Grid on\n",
    "    [ax.grid() for ax in axs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check our classification system: look at galaxies\n",
    "---\n",
    "\n",
    "Plot 2D maps showing:\n",
    "* WHAV* classification\n",
    "* BPT classification (total)\n",
    "* Total HALPHA EW \n",
    "* Number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lzifu.catid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gal = 487027\n",
    "df_gal = df_lzifu[df_lzifu.catid == gal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gals = []\n",
    "\n",
    "# Plot an SDSS image too \n",
    "_, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "plot_sdss_image(df_gal, ax=ax)\n",
    "\n",
    "rc(\"font\",**{\"family\": \"serif\", \"size\": 8})\n",
    "\n",
    "# Plot 2D maps showing each quantity across the galaxy\n",
    "col_z_list = \"WHAV* (numeric)\", \"BPT (numeric) (total)\", \"HALPHA EW (total)\", \"Number of components\"\n",
    "fig, axs = plt.subplots(2, 2, squeeze=True, figsize=(18, 10))\n",
    "for cc, col_z in enumerate(col_z_list):\n",
    "    # Plot the number of components fitted.\n",
    "    plot2dmap(df_gal=df_gal, bin_type=\"default\", survey=\"sami\",\n",
    "              PA_deg=0,\n",
    "              col_z=col_z,\n",
    "              ax=axs.flat[cc], plot_colorbar=True, cax_orientation=\"vertical\", show_title=False)\n",
    "\n",
    "# Reset font size\n",
    "rc(\"font\",**{\"family\": \"serif\", \"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
