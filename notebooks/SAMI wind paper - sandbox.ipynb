{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.visualization import hist\n",
    "from tqdm import tqdm\n",
    "\n",
    "from spaxelsleuth.loaddata.lzifu import load_lzifu_galaxies\n",
    "from spaxelsleuth.loaddata.sami import load_sami_galaxies\n",
    "from spaxelsleuth.plotting.plottools import plot_empty_BPT_diagram\n",
    "from spaxelsleuth.plotting.plottools import vmin_fn, vmax_fn, label_fn, cmap_fn, fname_fn\n",
    "from spaxelsleuth.plotting.plottools import bpt_colours, bpt_labels, whav_colors, whav_labels\n",
    "from spaxelsleuth.plotting.plottools import morph_labels, morph_ticks\n",
    "from spaxelsleuth.plotting.plottools import ncomponents_labels, ncomponents_colours\n",
    "from spaxelsleuth.plotting.plottools import component_labels, component_colours\n",
    "from spaxelsleuth.plotting.plotgalaxies import plot2dhistcontours, plot2dscatter, plot2dcontours\n",
    "from spaxelsleuth.plotting.plot2dmap import plot2dmap\n",
    "from spaxelsleuth.plotting.sdssimg import plot_sdss_image\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import rc, rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "rc(\"text\", usetex=False)\n",
    "rc(\"font\",**{\"family\": \"serif\", \"size\": 14})\n",
    "rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "rcParams[\"savefig.format\"] = \"pdf\"\n",
    "plt.ion()\n",
    "plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "fig_path = \"/priv/meggs3/u5708159/SAMI/figs/paper/\"\n",
    "savefigs = True\n",
    "bin_type = \"default\"    # Options: \"default\" or \"adaptive\" for Voronoi binning\n",
    "ncomponents = \"recom\"   # Options: \"1\" or \"recom\"\n",
    "eline_SNR_min = 3       # Minimum S/N of emission lines to accept\n",
    "plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: KS test \n",
    "---\n",
    "The empirical distribution function is given by\n",
    "\n",
    "$$F(x) = \\frac{(\\rm{number\\,of\\,samples\\,in\\,the\\,distribution} d {\\rm with\\,value} \\leq x)}{n}$$\n",
    "\n",
    "for $x \\in [x_{\\min}, x_{\\max}]$.\n",
    "\n",
    "\n",
    "The KS statistic is given by\n",
    "\n",
    "$$D_{n,m} = \\sup_x |F_{1,n}(x) - F_{2,n}(x)|$$\n",
    "\n",
    "for 2 samples $d_1$ and $d_2$ with sizes $n$ and $m$ respectively.\n",
    "\n",
    "The null hypothesis that samples $d_1$ and $d_2$ are drawn from the same distribution can be rejected at confidence level $\\alpha$ if \n",
    "\n",
    "$$D_{n,m} > \\sqrt{-\\ln\\left(\\frac{\\alpha}{2}\\right) \\frac{1}{2}} \\sqrt{\\frac{n + m}{nm}}$$\n",
    "\n",
    "However, because the KS test is sensitive to the *maximum* deviation between the two distributions, it may become overly sensitive when $n$ or $m$ are large. Avery et al. use the KS test effectively, but their sample sizes are only a couple of 1000, whereas our sample sizes are over 180,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small sample: the null hypothesis cannot be rejected at a 5.000% level (p-value = 90.84105%)\n"
     ]
    }
   ],
   "source": [
    "# Generate some random numbers \n",
    "d1 = np.random.normal(loc=0, scale=10, size=100)\n",
    "d2 = np.random.normal(loc=0, scale=10, size=100)\n",
    "\n",
    "# Run the 2-sample KS test \n",
    "r = ks_2samp(d1, d2)\n",
    "\n",
    "alpha = 0.05\n",
    "if r.pvalue < alpha:\n",
    "    print(f\"Small sample: the null hypothesis is rejected at a {alpha * 100:.3f}% level (p-value = {r.pvalue * 100:.5f}%)\")\n",
    "else:\n",
    "    print(f\"Small sample: the null hypothesis cannot be rejected at a {alpha * 100:.3f}% level (p-value = {r.pvalue * 100:.5f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large sample: the null hypothesis cannot be rejected at a 5.000% level (p-value = 80.96747%)\n"
     ]
    }
   ],
   "source": [
    "# Generate some random numbers \n",
    "d1 = np.random.normal(loc=0, scale=10, size=100000)\n",
    "d2 = np.random.normal(loc=0, scale=10.5, size=1000)\n",
    "\n",
    "# Run the 2-sample KS test \n",
    "r = ks_2samp(d1, d2)\n",
    "\n",
    "alpha = 0.05\n",
    "if r.pvalue < alpha:\n",
    "    print(f\"Large sample: the null hypothesis is rejected at a {alpha * 100:.3f}% level (p-value = {r.pvalue * 100:.5f}%)\")\n",
    "else:\n",
    "    print(f\"Large sample: the null hypothesis cannot be rejected at a {alpha * 100:.3f}% level (p-value = {r.pvalue * 100:.5f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: Anderson-Darling test\n",
    "---\n",
    "This test is similar to the KS test in that it is based on the empirical distribution function, however it is more sensitive to the tails in the distribution.\n",
    "\n",
    "`andersom_ksamp` returns the value of the AD statistic, plus \"critical values\" corresponding to various significance levels from 25% to 0.1%. If the value of the statistic is *larger* than the critical value for e.g. 2.5%, this means that we can reject the null hypothesis (that the samples are drawn from the same distribution) at a 2.5% level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import anderson_ksamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large sample: the null hypothesis is rejected at a 5.000% level (p-value = 1.36994%)\n"
     ]
    }
   ],
   "source": [
    "# Generate some random numbers \n",
    "d1 = np.random.normal(loc=0, scale=10, size=100000)\n",
    "d2 = np.random.normal(loc=0, scale=10.5, size=1000)\n",
    "d3 = np.random.normal(loc=0, scale=10.5, size=500)\n",
    "\n",
    "# Run the 2-sample KS test \n",
    "r = anderson_ksamp([d1, d2, d3])\n",
    "alpha = 0.05\n",
    "if r.significance_level < alpha:\n",
    "    print(f\"Large sample: the null hypothesis is rejected at a {alpha * 100:.3f}% level (p-value = {r.significance_level * 100:.5f}%)\")\n",
    "else:\n",
    "    print(f\"Large sample: the null hypothesis cannot be rejected at a {alpha * 100:.3f}% level (p-value = {r.significance_level * 100:.5f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: S/N in emission line fits \n",
    "---\n",
    "* 3 emission line components w/ fixed S/N ratio each\n",
    "* use mpfit to fit the lines \n",
    "* what is the formal S/N on the fitted emission lines?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpfit import mpfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, A, mu, sigma):\n",
    "    return A * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our emission lines \n",
    "x_vals = np.linspace(-500, 500, 200)\n",
    "\n",
    "# Component 1\n",
    "A_1 = 10\n",
    "mu_1 = 0\n",
    "sigma_1 = 40\n",
    "f_1 = gaussian(x_vals, A_1, mu_1, sigma_1)\n",
    "\n",
    "# Component 2\n",
    "A_2 = 5\n",
    "mu_2 = -10\n",
    "sigma_2 = 100\n",
    "f_2 = gaussian(x_vals, A_2, mu_2, sigma_2)\n",
    "\n",
    "# Component 3\n",
    "A_3 = 3 \n",
    "mu_3 = -20\n",
    "sigma_3 = 150\n",
    "f_3 = gaussian(x_vals, A_3, mu_3, sigma_3)\n",
    "\n",
    "spec_1comp_no_noise = f_1\n",
    "spec_2comp_no_noise = f_1 + f_2 \n",
    "spec_3comp_no_noise = f_1 + f_2 + f_3\n",
    "\n",
    "# # Inspect result\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "# ax.plot(x_vals, f_1, label=\"Component 1\", linestyle=\":\")\n",
    "# ax.plot(x_vals, f_2, label=\"Component 2\", linestyle=\":\")\n",
    "# ax.plot(x_vals, f_3, label=\"Component 3\", linestyle=\":\")\n",
    "# ax.plot(x_vals, spec_1comp_no_noise, label=\"1 components\", linestyle=\"-\", linewidth=0.5)\n",
    "# ax.plot(x_vals, spec_2comp_no_noise, label=\"2 components\", linestyle=\"-\", linewidth=0.5)\n",
    "# ax.plot(x_vals, spec_3comp_no_noise, label=\"3 components\", linestyle=\"-\", linewidth=0.5)\n",
    "# ax.plot(x_vals, spec_1comp, label=\"1 components (noise)\", linestyle=\"-\")\n",
    "# ax.plot(x_vals, spec_2comp, label=\"2 components (noise)\", linestyle=\"-\")\n",
    "# ax.plot(x_vals, spec_3comp, label=\"3 components (noise)\", linestyle=\"-\")\n",
    "# ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Fit using mpfit \n",
    "################################################################################\n",
    "# The model we fit to the data\n",
    "def F(x, p):\n",
    "    A_1, mu_1, sigma_1, A_2, mu_2, sigma_2, A_3, mu_3, sigma_3 = p\n",
    "    return gaussian(x, A_1, mu_1, sigma_1) + gaussian(x, A_2, mu_2, sigma_2) + gaussian(x, A_3, mu_3, sigma_3)\n",
    "\n",
    "############################################################################\n",
    "# Function to be passed into mpfit\n",
    "def minfunc(p, fjac=None, x=None, y=None, err=None):\n",
    "    # The model evaluated at the provided x values with parameters stored in p\n",
    "    model = F(x, p)\n",
    "    # The deviates are the differences between the measurements y and the model\n",
    "    # evaluated at each point x normalised by the standard deviation in the\n",
    "    # measurement.\n",
    "    deviates = np.array((y - model) / err, dtype=float)\n",
    "    # We return p status flag and the deviates.\n",
    "    return 0, deviates\n",
    "\n",
    "############################################################################\n",
    "# Parameters to be passed into the fitting function\n",
    "parinfo = [{\n",
    "    'value': 0,\n",
    "    'fixed': False,\n",
    "    'limited': [False, False],\n",
    "    'limits':[0, 0],\n",
    "    'parname':'',\n",
    "    'mpside':2,\n",
    "    'mpprint':0\n",
    "} for ii in range(3 * 3)]\n",
    "parinfo[0]['parname'] = 'A_1'\n",
    "parinfo[1]['parname'] = 'mu_1'\n",
    "parinfo[2]['parname'] = 'sigma_1'\n",
    "parinfo[3]['parname'] = 'A_2'\n",
    "parinfo[4]['parname'] = 'mu_2'\n",
    "parinfo[5]['parname'] = 'sigma_2'\n",
    "parinfo[6]['parname'] = 'A_3'\n",
    "parinfo[7]['parname'] = 'mu_3'\n",
    "parinfo[8]['parname'] = 'sigma_3'\n",
    "\n",
    "############################################################################\n",
    "# Parameter constraints\n",
    "# Amplitude: must be positive\n",
    "for ii in [0, 3, 6]:\n",
    "    parinfo[ii]['limited'] = [True, True]\n",
    "    parinfo[ii]['limits'] = [0, 100.]\n",
    "\n",
    "# Mean: constrained to be inside the wavelength window\n",
    "for ii in [1, 4, 7]:\n",
    "    parinfo[3]['limited'] = [True, True]\n",
    "    parinfo[4]['limits'] = [-500., +500.]\n",
    "\n",
    "# Sigma\n",
    "for ii in [2, 5, 8]:\n",
    "    parinfo[ii]['limited'] = [True, True]\n",
    "parinfo[2]['limits'] = [0, 80.]\n",
    "parinfo[5]['limits'] = [80, 200.]\n",
    "parinfo[8]['limits'] = [200, 250.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40446b80f91e41c7ad13d405400895b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  0%|          | 3/1000 [00:01<05:39,  2.94it/s]/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in double_scalars\n",
      " 10%|█         | 104/1000 [00:06<01:15, 11.79it/s]/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "100%|██████████| 1000/1000 [01:02<00:00, 15.98it/s]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Run the fit: 1 component\n",
    "################################################################################\n",
    "SN_comp_1_vals_1comp = []\n",
    "SN_comp_2_vals_1comp = []\n",
    "SN_comp_3_vals_1comp = []\n",
    "niters = 1000\n",
    "for nn in tqdm(range(niters)):\n",
    "    # Add random noise\n",
    "    noise_stdv = 0.1\n",
    "    spec_err = np.full_like(x_vals, noise_stdv)\n",
    "    spec_1comp = spec_1comp_no_noise + np.random.normal(loc=0, scale=spec_err)\n",
    "    parnames = {\n",
    "        'x': x_vals,\n",
    "        'y': spec_1comp,\n",
    "        'err': spec_err\n",
    "    }\n",
    "\n",
    "    # Run mpfit\n",
    "    p0 = np.array([1., 0., 80.] + [0., 0., 100.] + [0., 0., 200.])\n",
    "    fit = mpfit.mpfit(minfunc, p0, functkw=parnames, parinfo=parinfo, quiet=1)\n",
    "    p_fit = fit.params\n",
    "    p_err = fit.perror\n",
    "    spec_fit = F(x_vals, p_fit)\n",
    "\n",
    "    if nn == 0:\n",
    "        # Inspect result\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.plot(x_vals, f_1, label=\"Component 1\")\n",
    "        ax.plot(x_vals, f_2, label=\"Component 2\")\n",
    "        ax.plot(x_vals, f_3, label=\"Component 3\")\n",
    "        ax.plot(x_vals, parnames[\"y\"], label=\"Spectrum\")\n",
    "        ax.plot(x_vals, spec_fit, \"k\", label=\"Fit\")\n",
    "        ax.legend()\n",
    "\n",
    "    # Compute S/N in the fitted fluxes\n",
    "    A_1_fit, mu_1_fit, sigma_1_fit, A_2_fit, mu_2_fit, sigma_2_fit, A_3_fit, mu_3_fit, sigma_3_fit = p_fit\n",
    "    A_1_err, mu_1_err, sigma_1_err, A_2_err, mu_2_err, sigma_2_err, A_3_err, mu_3_err, sigma_3_err = p_err\n",
    "    flux_1_fit = np.sqrt(2 * np.pi) * A_1_fit * sigma_1_fit\n",
    "    flux_1_fit_err = np.sqrt(2 * np.pi * (A_1**2 * sigma_1_err**2 + sigma_1**2 * A_1_err**2) )\n",
    "    flux_2_fit = np.sqrt(2 * np.pi) * A_2_fit * sigma_2_fit\n",
    "    flux_2_fit_err = np.sqrt(2 * np.pi * (A_2**2 * sigma_2_err**2 + sigma_2**2 * A_2_err**2) )\n",
    "    flux_3_fit = np.sqrt(2 * np.pi) * A_3_fit * sigma_3_fit\n",
    "    flux_3_fit_err = np.sqrt(2 * np.pi * (A_3**2 * sigma_3_err**2 + sigma_3**2 * A_3_err**2) )\n",
    "\n",
    "    # Save the S/N\n",
    "    SN_comp_1_vals_1comp.append(flux_1_fit / flux_1_fit_err)\n",
    "    SN_comp_2_vals_1comp.append(flux_2_fit / flux_2_fit_err)\n",
    "    SN_comp_3_vals_1comp.append(flux_3_fit / flux_3_fit_err)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6824a7ff2254198969bc6fdccc313a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  1%|          | 9/1000 [00:00<00:39, 24.94it/s]/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "100%|██████████| 1000/1000 [01:03<00:00, 15.64it/s]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Run the fit: 2 components\n",
    "################################################################################\n",
    "SN_comp_1_vals_2comp = []\n",
    "SN_comp_2_vals_2comp = []\n",
    "SN_comp_3_vals_2comp = []\n",
    "niters = 1000\n",
    "for nn in tqdm(range(niters)):\n",
    "    # Add random noise\n",
    "    noise_stdv = 0.1\n",
    "    spec_err = np.full_like(x_vals, noise_stdv)\n",
    "    spec_2comp = spec_2comp_no_noise + np.random.normal(loc=0, scale=spec_err)\n",
    "    parnames = {\n",
    "        'x': x_vals,\n",
    "        'y': spec_2comp,\n",
    "        'err': spec_err\n",
    "    }\n",
    "\n",
    "    # Run mpfit\n",
    "    p0 = np.array([1., 0., 80.] + [0., 0., 100.] + [0., 0., 200.])\n",
    "    fit = mpfit.mpfit(minfunc, p0, functkw=parnames, parinfo=parinfo, quiet=1)\n",
    "    p_fit = fit.params\n",
    "    p_err = fit.perror\n",
    "\n",
    "    if nn == 0:\n",
    "        # Inspect result\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        spec_fit = F(x_vals, p_fit)\n",
    "        ax.plot(x_vals, f_1, label=\"Component 1\")\n",
    "        ax.plot(x_vals, f_2, label=\"Component 2\")\n",
    "        ax.plot(x_vals, f_3, label=\"Component 3\")\n",
    "        ax.plot(x_vals, parnames[\"y\"], label=\"Spectrum\")\n",
    "        ax.plot(x_vals, spec_fit, \"k\", label=\"Fit\")\n",
    "        ax.legend()\n",
    "\n",
    "    # Compute S/N in the fitted fluxes\n",
    "    A_1_fit, mu_1_fit, sigma_1_fit, A_2_fit, mu_2_fit, sigma_2_fit, A_3_fit, mu_3_fit, sigma_3_fit = p_fit\n",
    "    A_1_err, mu_1_err, sigma_1_err, A_2_err, mu_2_err, sigma_2_err, A_3_err, mu_3_err, sigma_3_err = p_err\n",
    "    flux_1_fit = np.sqrt(2 * np.pi) * A_1_fit * sigma_1_fit\n",
    "    flux_1_fit_err = np.sqrt(2 * np.pi * (A_1**2 * sigma_1_err**2 + sigma_1**2 * A_1_err**2) )\n",
    "    flux_2_fit = np.sqrt(2 * np.pi) * A_2_fit * sigma_2_fit\n",
    "    flux_2_fit_err = np.sqrt(2 * np.pi * (A_2**2 * sigma_2_err**2 + sigma_2**2 * A_2_err**2) )\n",
    "    flux_3_fit = np.sqrt(2 * np.pi) * A_3_fit * sigma_3_fit\n",
    "    flux_3_fit_err = np.sqrt(2 * np.pi * (A_3**2 * sigma_3_err**2 + sigma_3**2 * A_3_err**2) )\n",
    "\n",
    "    # Save the S/N\n",
    "    SN_comp_1_vals_2comp.append(flux_1_fit / flux_1_fit_err)\n",
    "    SN_comp_2_vals_2comp.append(flux_2_fit / flux_2_fit_err)\n",
    "    SN_comp_3_vals_2comp.append(flux_3_fit / flux_3_fit_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e98c030eb14deaa5293aa1e43f0694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:02<00:00, 15.93it/s]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Run the fit: 3 components\n",
    "################################################################################\n",
    "SN_comp_1_vals_2comp = []\n",
    "SN_comp_2_vals_2comp = []\n",
    "SN_comp_3_vals_2comp = []\n",
    "niters = 1000\n",
    "for nn in tqdm(range(niters)):\n",
    "    # Add random noise\n",
    "    noise_stdv = 0.1\n",
    "    spec_err = np.full_like(x_vals, noise_stdv)\n",
    "    spec_3comp = spec_3comp_no_noise + np.random.normal(loc=0, scale=spec_err)\n",
    "    parnames = {\n",
    "        'x': x_vals,\n",
    "        'y': spec_3comp,\n",
    "        'err': spec_err\n",
    "    }\n",
    "\n",
    "    # Run mpfit\n",
    "    p0 = np.array([1., 0., 80.] + [0., 0., 100.] + [0., 0., 200.])\n",
    "    fit = mpfit.mpfit(minfunc, p0, functkw=parnames, parinfo=parinfo, quiet=1)\n",
    "    p_fit = fit.params\n",
    "    p_err = fit.perror\n",
    "\n",
    "    if nn == 0:\n",
    "        # Inspect result\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        spec_fit = F(x_vals, p_fit)\n",
    "        ax.plot(x_vals, f_1, label=\"Component 1\")\n",
    "        ax.plot(x_vals, f_2, label=\"Component 2\")\n",
    "        ax.plot(x_vals, f_3, label=\"Component 3\")\n",
    "        ax.plot(x_vals, parnames[\"y\"], label=\"Spectrum\")\n",
    "        ax.plot(x_vals, spec_fit, \"k\", label=\"Fit\")\n",
    "        ax.legend()\n",
    "\n",
    "    # Compute S/N in the fitted fluxes\n",
    "    A_1_fit, mu_1_fit, sigma_1_fit, A_2_fit, mu_2_fit, sigma_2_fit, A_3_fit, mu_3_fit, sigma_3_fit = p_fit\n",
    "    A_1_err, mu_1_err, sigma_1_err, A_2_err, mu_2_err, sigma_2_err, A_3_err, mu_3_err, sigma_3_err = p_err\n",
    "    flux_1_fit = np.sqrt(2 * np.pi) * A_1_fit * sigma_1_fit\n",
    "    flux_1_fit_err = np.sqrt(2 * np.pi * (A_1**2 * sigma_1_err**2 + sigma_1**2 * A_1_err**2) )\n",
    "    flux_2_fit = np.sqrt(2 * np.pi) * A_2_fit * sigma_2_fit\n",
    "    flux_2_fit_err = np.sqrt(2 * np.pi * (A_2**2 * sigma_2_err**2 + sigma_2**2 * A_2_err**2) )\n",
    "    flux_3_fit = np.sqrt(2 * np.pi) * A_3_fit * sigma_3_fit\n",
    "    flux_3_fit_err = np.sqrt(2 * np.pi * (A_3**2 * sigma_3_err**2 + sigma_3**2 * A_3_err**2) )\n",
    "\n",
    "    # Save the S/N\n",
    "    SN_comp_1_vals_2comp.append(flux_1_fit / flux_1_fit_err)\n",
    "    SN_comp_2_vals_2comp.append(flux_2_fit / flux_2_fit_err)\n",
    "    SN_comp_3_vals_2comp.append(flux_3_fit / flux_3_fit_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6d609defcb43b095561ec85e734db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'SN_comp_1_vals_3comp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e81e94b38fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSN_comp_1_vals_1comp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1-component spectrum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSN_comp_1_vals_2comp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2-component spectrum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSN_comp_1_vals_3comp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"3-component spectrum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"S/N in component 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SN_comp_1_vals_3comp' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot histograms showing the S/N in component 1 for the 1-component spectrum and the 2-component spectrum\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "hist(np.array(SN_comp_1_vals_1comp), bins=50, range=(0, 300), label=\"1-component spectrum\", histtype=\"step\")\n",
    "hist(np.array(SN_comp_1_vals_2comp), bins=50, range=(0, 300), label=\"2-component spectrum\", histtype=\"step\")\n",
    "hist(np.array(SN_comp_1_vals_3comp), bins=50, range=(0, 300), label=\"3-component spectrum\", histtype=\"step\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"S/N in component 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMI dataset \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:853: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: in load_sami_galaxies: NOT correcting Halpha and HALPHA EW for extinction!\n"
     ]
    }
   ],
   "source": [
    "# Load the sample\n",
    "df = load_sami_galaxies(ncomponents=ncomponents,\n",
    "                        bin_type=bin_type,\n",
    "                        eline_SNR_min=eline_SNR_min, \n",
    "                        vgrad_cut=False,\n",
    "                        correct_extinction=False,\n",
    "                        sigma_gas_SNR_cut=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not computing WHAV* categories because ncomponents is not 3\n",
      "WARNING: in load_sami_galaxies: NOT correcting Halpha and HALPHA EW for extinction!\n"
     ]
    }
   ],
   "source": [
    "# Load the sample\n",
    "df_1comp = load_sami_galaxies(ncomponents=\"1\",\n",
    "                        bin_type=bin_type,\n",
    "                        eline_SNR_min=eline_SNR_min, \n",
    "                        vgrad_cut=False,\n",
    "                        correct_extinction=False,\n",
    "                        sigma_gas_SNR_cut=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a separate DataFrame only containing star-forming spaxels\n",
    "df_SF = df.copy()\n",
    "df_SF = df_SF[df_SF[\"BPT (total)\"] == \"SF\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a separate DataFrame only containing star-forming spaxels\n",
    "df_SF_1comp = df_1comp.copy()\n",
    "df_SF_1comp = df_SF_1comp[df_SF_1comp[\"BPT (total)\"] == \"SF\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy fig. 2 of Law+2020: how does having spectrally resolved emission line components change this figure? Compare the 1-component and multi-component fits.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ea3af2ce234972bef239d0f113afd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: /priv/meggs3/u5708159/SAMI/figs/paper/BPT_SAMI_log_sigma_gas_1comp.pdf\n"
     ]
    }
   ],
   "source": [
    "col_z = \"log sigma_gas\"\n",
    "fig, axs, cax = plot_empty_BPT_diagram(colorbar=True, nrows=1, include_Law2021=True)\n",
    "\n",
    "# Plot 2D histograms of the subset\n",
    "plot2dhistcontours(df_1comp, col_x=\"log N2 (total)\", col_y=\"log O3 (total)\", col_z=f\"{col_z} (component 0)\", log_z=False, vmin=np.log10(20), vmax=np.log10(150), cmap=\"Spectral_r\", ax=axs[0], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "plot2dhistcontours(df_1comp, col_x=\"log S2 (total)\", col_y=\"log O3 (total)\", col_z=f\"{col_z} (component 0)\", log_z=False, vmin=np.log10(20), vmax=np.log10(150), cmap=\"Spectral_r\", ax=axs[1], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "plot2dhistcontours(df_1comp, col_x=\"log O1 (total)\", col_y=\"log O3 (total)\", col_z=f\"{col_z} (component 0)\", log_z=False, vmin=np.log10(20), vmax=np.log10(150), cmap=\"Spectral_r\", ax=axs[2], nbins=100, contours=True, colors=\"white\", cax=cax, plot_colorbar=True)\n",
    "\n",
    "# Decorations\n",
    "[ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "\n",
    "\n",
    "# Grid on\n",
    "[ax.grid() for ax in axs]\n",
    "axs[1].set_title(\"1-component fit\")\n",
    "\n",
    "# Save\n",
    "if savefigs:\n",
    "    fname = os.path.join(fig_path, f\"BPT_SAMI_{fname_fn(col_z)}_1comp.pdf\")\n",
    "    fig.savefig(fname, bbox_inches=\"tight\", format=\"pdf\")\n",
    "    print(f\"File saved at: {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c876a3e482e4ab1bc625d591b64e1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: /priv/meggs3/u5708159/SAMI/figs/paper/BPT_SAMI_log_sigma_gas_multi-component.pdf\n"
     ]
    }
   ],
   "source": [
    "col_z = \"log sigma_gas\"\n",
    "fig, axs_all, caxs = plot_empty_BPT_diagram(colorbar=True, nrows=3, include_Law2021=True)\n",
    "for ii in range(3):\n",
    "    axs = axs_all[ii * 3:ii * 3 + 3]\n",
    "\n",
    "    # Plot 2D histograms of the subset\n",
    "    plot2dhistcontours(df, col_x=\"log N2 (total)\", col_y=\"log O3 (total)\", col_z=f\"{col_z} (component {ii})\", log_z=False, vmin=np.log10(20), vmax=np.log10(150), cmap=\"Spectral_r\", ax=axs[0], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "    plot2dhistcontours(df, col_x=\"log S2 (total)\", col_y=\"log O3 (total)\", col_z=f\"{col_z} (component {ii})\", log_z=False, vmin=np.log10(20), vmax=np.log10(150), cmap=\"Spectral_r\", ax=axs[1], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "    plot2dhistcontours(df, col_x=\"log O1 (total)\", col_y=\"log O3 (total)\", col_z=f\"{col_z} (component {ii})\", log_z=False, vmin=np.log10(20), vmax=np.log10(150), cmap=\"Spectral_r\", ax=axs[2], nbins=100, contours=True, colors=\"white\", cax=caxs[ii], plot_colorbar=True)\n",
    "\n",
    "    # Decorations\n",
    "    [ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "    axs[0].text(s=f\"Component {ii + 1}\", x=0.05, y=0.95, transform=axs[0].transAxes, fontsize=\"small\")\n",
    "\n",
    "    # Grid on\n",
    "    [ax.grid() for ax in axs]\n",
    "\n",
    "# Save\n",
    "axs_all[1].set_title(\"Multi-component fit\")\n",
    "if savefigs:\n",
    "    fname = os.path.join(fig_path, f\"BPT_SAMI_{fname_fn(col_z)}_multi-component.pdf\")\n",
    "    fig.savefig(fname, bbox_inches=\"tight\", format=\"pdf\")\n",
    "    print(f\"File saved at: {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed71037b7e94e28b92244b3d82a5691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_z = \"count\"\n",
    "fig, axs_all, caxs = plot_empty_BPT_diagram(colorbar=True, nrows=3, include_Law2021=True)\n",
    "for ii in range(3):\n",
    "    axs = axs_all[ii * 3:ii * 3 + 3]\n",
    "    \n",
    "    df_subset = df[df[\"Number of components\"] == ii + 1]\n",
    "\n",
    "    # Plot 2D histograms of the subset\n",
    "    plot2dhistcontours(df_subset, col_x=\"log N2 (total)\", col_y=\"log O3 (total)\", col_z=\"count\", log_z=True, vmin=10, vmax=1e3, ax=axs[0], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "    plot2dhistcontours(df_subset, col_x=\"log S2 (total)\", col_y=\"log O3 (total)\", col_z=\"count\", log_z=True, vmin=10, vmax=1e3, ax=axs[1], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "    plot2dhistcontours(df_subset, col_x=\"log O1 (total)\", col_y=\"log O3 (total)\", col_z=\"count\", log_z=True, vmin=10, vmax=1e3, ax=axs[2], nbins=100, contours=True, colors=\"white\", cax=caxs[ii], plot_colorbar=True)\n",
    "\n",
    "    # Decorations\n",
    "    [ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "    axs[0].text(s=f\"{ii + 1}-component spaxels\", x=0.05, y=0.95, transform=axs[0].transAxes, fontsize=\"small\")\n",
    "\n",
    "    # Grid on\n",
    "    [ax.grid() for ax in axs]\n",
    "\n",
    "# Save\n",
    "if savefigs:\n",
    "    fname = os.path.join(fig_path, f\"BPT_SAMI_{fname_fn(col_z)}_multi-component.pdf\")\n",
    "    fig.savefig(fname, bbox_inches=\"tight\", format=\"pdf\")\n",
    "    print(f\"File saved at: {fname}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate fig. 6 of Law+2020\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5664eb6f169845df84dc652f62ca298d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8925600da944f4a703b1f67a15263c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055219520fe2401085f5ac5381ca1374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69269e0665e1434483fbb65fd755ced5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf015058c1c34877b30bf93e75378b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c260c74c7a24f0c9e1782c4c094db22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for bpt in bpt_labels:\n",
    "    df_subset = df[df[\"BPT (total)\"] == bpt]\n",
    "    df_subset_1comp = df_1comp[df_1comp[\"BPT (total)\"] == bpt]\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7.5, 5))\n",
    "    hist(df_subset_1comp[\"sigma_gas (component 0)\"], ax=ax, color=\"k\", bins=\"scott\", histtype=\"step\", range=(0, 150), label=\"1-component fit\", normed=False)\n",
    "    for ii in range(3):\n",
    "        hist(df_subset[f\"sigma_gas (component {ii})\"], ax=ax, color=component_colours[ii], bins=\"scott\", histtype=\"step\", range=(0, 150), label=f\"Multi-component fit (component {ii +1})\", normed=False)\n",
    "    ax.set_ylabel(r\"$N$\")\n",
    "    ax.set_xlabel(r\"$\\sigma_{\\rm gas}$\")\n",
    "    ax.set_title(bpt)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.legend(fontsize=\"small\", loc=\"center left\", bbox_to_anchor=(1.1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute: fraction of spaxels with $\\Delta\\sigma < 0$ in the multi-component fits and in the single-component fits\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-component fits:\n",
      "97.8871396280287% of 1-component SF-like spaxels have component 0 with dsigma < 0\n",
      "2.1128603719712893% of 1-component SF-like spaxels have component 0 with dsigma > 0\n",
      "99.48364888123923% of 2-component SF-like spaxels have component 0 with dsigma < 0\n",
      "0.5163511187607573% of 2-component SF-like spaxels have component 0 with dsigma > 0\n",
      "99.64945080626315% of 3-component SF-like spaxels have component 0 with dsigma < 0\n",
      "0.35054919373685445% of 3-component SF-like spaxels have component 0 with dsigma > 0\n"
     ]
    }
   ],
   "source": [
    "# How many SF-like spaxels have dsigma < 0?\n",
    "print(\"Multi-component fits:\")\n",
    "\n",
    "Ntot = df_SF[(df_SF[\"Number of components\"] == 1) & (~df_SF[\"sigma_gas - sigma_* (component 0)\"].isna())].shape[0]\n",
    "N = df_SF[(df_SF[\"Number of components\"] == 1) & (df_SF[\"sigma_gas - sigma_* (component 0)\"] < 0)].shape[0]\n",
    "N2 = df_SF[(df_SF[\"Number of components\"] == 1) & (df_SF[\"sigma_gas - sigma_* (component 0)\"] > 0)].shape[0]\n",
    "\n",
    "print(f\"{N / Ntot * 100}% of 1-component SF-like spaxels have component 0 with dsigma < 0\")\n",
    "print(f\"{N2 / Ntot * 100}% of 1-component SF-like spaxels have component 0 with dsigma > 0\")\n",
    "\n",
    "Ntot = df_SF[(df_SF[\"Number of components\"] == 2) & (~df_SF[\"sigma_gas - sigma_* (component 0)\"].isna())].shape[0]\n",
    "N = df_SF[(df_SF[\"Number of components\"] == 2) & (df_SF[\"sigma_gas - sigma_* (component 0)\"] < 0)].shape[0]\n",
    "N2 = df_SF[(df_SF[\"Number of components\"] == 2) & (df_SF[\"sigma_gas - sigma_* (component 0)\"] > 0)].shape[0]\n",
    "\n",
    "print(f\"{N / Ntot * 100}% of 2-component SF-like spaxels have component 0 with dsigma < 0\")\n",
    "print(f\"{N2 / Ntot * 100}% of 2-component SF-like spaxels have component 0 with dsigma > 0\")\n",
    "\n",
    "Ntot = df_SF[(df_SF[\"Number of components\"] == 3) & (~df_SF[\"sigma_gas - sigma_* (component 0)\"].isna())].shape[0]\n",
    "N = df_SF[(df_SF[\"Number of components\"] == 3) & (df_SF[\"sigma_gas - sigma_* (component 0)\"] < 0)].shape[0]\n",
    "N2 = df_SF[(df_SF[\"Number of components\"] == 3) & (df_SF[\"sigma_gas - sigma_* (component 0)\"] > 0)].shape[0]\n",
    "\n",
    "print(f\"{N / Ntot * 100}% of 3-component SF-like spaxels have component 0 with dsigma < 0\")\n",
    "print(f\"{N2 / Ntot * 100}% of 3-component SF-like spaxels have component 0 with dsigma > 0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-component fits:\n",
      "97.04416447459504% of 1-component SF-like spaxels have component 0 with dsigma < 0\n",
      "2.9558355254049564% of 1-component SF-like spaxels have component 0 with dsigma > 0\n"
     ]
    }
   ],
   "source": [
    "# How many SF-like spaxels have dsigma < 0?\n",
    "print(\"Single-component fits:\")\n",
    "\n",
    "Ntot = df_SF_1comp[(df_SF_1comp[\"Number of components\"] == 1) & (~df_SF_1comp[\"sigma_gas - sigma_* (component 0)\"].isna())].shape[0]\n",
    "N = df_SF_1comp[(df_SF_1comp[\"Number of components\"] == 1) & (df_SF_1comp[\"sigma_gas - sigma_* (component 0)\"] < 0)].shape[0]\n",
    "N2 = df_SF_1comp[(df_SF_1comp[\"Number of components\"] == 1) & (df_SF_1comp[\"sigma_gas - sigma_* (component 0)\"] > 0)].shape[0]\n",
    "\n",
    "print(f\"{N / Ntot * 100}% of 1-component SF-like spaxels have component 0 with dsigma < 0\")\n",
    "print(f\"{N2 / Ntot * 100}% of 1-component SF-like spaxels have component 0 with dsigma > 0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_z in [\"count\", \"Number of components\", \"BPT (numeric) (total)\"]:\n",
    "    fig, axs, cax = plot_empty_BPT_diagram(colorbar=True, nrows=1, include_Law2021=True)\n",
    "    \n",
    "    # Plot 2D histograms of the subset\n",
    "    plot2dhistcontours(df, col_x=\"log N2 (total)\", col_y=\"log O3 (total)\", col_z=col_z, log_z=True if col_z == \"count\" else False, vmin=1 if col_z == \"count\" else None, vmax=1e3 if col_z == \"count\" else None, ax=axs[0], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "    plot2dhistcontours(df, col_x=\"log S2 (total)\", col_y=\"log O3 (total)\", col_z=col_z, log_z=True if col_z == \"count\" else False, vmin=1 if col_z == \"count\" else None, vmax=1e3 if col_z == \"count\" else None, ax=axs[1], nbins=100, contours=True, colors=\"white\", plot_colorbar=False)\n",
    "    plot2dhistcontours(df, col_x=\"log O1 (total)\", col_y=\"log O3 (total)\", col_z=col_z, log_z=True if col_z == \"count\" else False, vmin=1 if col_z == \"count\" else None, vmax=1e3 if col_z == \"count\" else None, ax=axs[2], nbins=100, contours=True, colors=\"white\", cax=cax, plot_colorbar=True)\n",
    "\n",
    "    # Decorations\n",
    "    [ax.set_ylabel(\"\") for ax in axs[1:]]\n",
    "\n",
    "    # Grid on\n",
    "    [ax.grid() for ax in axs]\n",
    "    \n",
    "    # Save\n",
    "    if savefigs:\n",
    "        fname = os.path.join(fig_path, f\"BPT_SAMI_{fname_fn(col_z)}_1comp.pdf\")\n",
    "        fig.savefig(fname, bbox_inches=\"tight\", format=\"pdf\")\n",
    "        print(f\"File saved at: {fname}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We know that the fraction of spaxels with multiple/KD components increases as a function of SFR/SFR surface density. But at a fixed SFR/SFR surface density, only *some* spaxels have KD/multiple kinematic components. **Why is this?** What makes the spaxels with KD/multiple components *different* from those without?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 11833\n"
     ]
    }
   ],
   "source": [
    "# Pick spaxels within a narrow range of SFR surface density\n",
    "SFR_lower = -1.5\n",
    "SFR_upper = -1.25\n",
    "df_SF_subset = df_SF[(df_SF[\"log SFR surface density (component 0)\"] > SFR_lower) & (df_SF[\"log SFR surface density (component 0)\"] <= SFR_upper)]\n",
    "print(f\"N = {df_SF_subset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15083402912e4067b026c8a89231c19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b127dd548f414fa29a69ec5ff19717b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7328098f750144f898a87bcb688811e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py:6735: RuntimeWarning: All-NaN slice encountered\n",
      "  xmin = min(xmin, np.nanmin(xi))\n",
      "/pkg/linux/anaconda-20191122/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py:6736: RuntimeWarning: All-NaN slice encountered\n",
      "  xmax = max(xmax, np.nanmax(xi))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0967e0ca623248849cdbf8b331736243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5e0097cdca4855b70d5c8334b2a7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec04dbb936f04031a085b08034d4f7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66b97f1f75e41fb9b0882da6c07eb3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6f43e117054434a30784cdf37d95cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Halpha EW, SFR, SFR surface density\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "\n",
    "for cc, col_x in enumerate([\"log HALPHA EW (total)\", \"log SFR (component 0)\", \"log SFR surface density (component 0)\"]):\n",
    "    for ii in range(3):\n",
    "        cond = df_SF_subset[\"Number of components\"] == ii + 1\n",
    "        hist(df_SF_subset.loc[cond, col_x], density=True, histtype=\"step\",\n",
    "             ax=axs[cc], range=(vmin_fn(col_x), 100 if col_x.startswith(\"sigma\") else vmax_fn(col_x)),\n",
    "             bins=\"scott\",\n",
    "             label=f\"{ncomponents_labels[ii]} KD component{'s' if ii  > 1 else ''}\" + r\" ($N = %d$)\" % (df_SF_subset.loc[cond, col_x].shape[0]),\n",
    "             color=ncomponents_colours[ii + 1])\n",
    "    axs[cc].set_xlabel(label_fn(col_x))\n",
    "    axs[cc].set_yticklabels([]) if ii > 0 else None\n",
    "axs[0].axvline(np.log10(3), linestyle=\"--\", color=\"k\")\n",
    "axs[0].legend(fontsize=\"x-small\", loc=\"upper left\")\n",
    "axs[0].set_ylabel(r\"$N$ (normalised)\")\n",
    "fig.suptitle(r\"H$\\alpha$-derived quantities (SF spaxels only)\", y=0.94)\n",
    "\n",
    "if savefigs:\n",
    "    fname = os.path.join(fig_path, f\"hist_KDcomponents_HaEW_and_sigma_and_SFR_SF_only\")\n",
    "    print(f\"Saving to {fname}\")\n",
    "    fig.savefig(fname, bbox_inches=\"tight\")\n",
    "\n",
    "# Systematic quantities\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "for cc, col_x in enumerate([\"Bin size (square kpc)\", \"z_spec\", \"Inclination i (degrees)\"]):\n",
    "    for ii in range(3):\n",
    "        cond = df_SF_subset[\"Number of components\"] == ii + 1\n",
    "        hist(df_SF_subset.loc[cond, col_x], density=True, histtype=\"step\",\n",
    "             ax=axs[cc],\n",
    "             bins=\"scott\", \n",
    "             range=(0, 90) if col_x == \"Inclination i (degrees)\" else None,\n",
    "             label=f\"{ncomponents_labels[ii]} KD component{'s' if ii > 1 else ''}\" + r\" ($N = %d$)\" % (df_SF_subset.loc[cond].shape[0]),\n",
    "             color=ncomponents_colours[ii + 1])\n",
    "    axs[cc].set_xlabel(label_fn(col_x))\n",
    "    axs[cc].set_yticklabels([]) if cc > 0 else None\n",
    "# axs[0].legend(fontsize=\"x-small\", loc=\"upper right\")\n",
    "axs[0].set_ylabel(r\"$N$ (normalised)\")\n",
    "fig.suptitle(\"Systematics (SF spaxels only)\", y=0.94)\n",
    "\n",
    "if savefigs:\n",
    "    fname = os.path.join(fig_path, f\"hist_KDcomponents_systematic_SF_only.pdf\")\n",
    "    print(f\"Saving to {fname}\")\n",
    "    fig.savefig(fname, bbox_inches=\"tight\", format=\"pdf\")\n",
    "\n",
    "# Systematic quantities\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "for cc, col_x in enumerate([\"HALPHA S/N (total)\", \"HALPHA S/N (component 0)\", \"HALPHA S/N (component 1)\", \"HALPHA S/N (component 2)\"]):\n",
    "    for ii in range(3):\n",
    "        cond = df_SF_subset[\"Number of components\"] == ii + 1\n",
    "        hist(df_SF_subset.loc[cond, col_x], density=True, histtype=\"step\",\n",
    "             ax=axs[cc],\n",
    "             bins=\"scott\", \n",
    "             range=(0, 90) if col_x == \"Inclination i (degrees)\" else None,\n",
    "             label=f\"{ncomponents_labels[ii]} KD component{'s' if ii > 1 else ''}\" + r\" ($N = %d$)\" % (df_SF_subset.loc[cond].shape[0]),\n",
    "             color=ncomponents_colours[ii + 1])\n",
    "    axs[cc].set_xlabel(label_fn(col_x))\n",
    "    axs[cc].set_yticklabels([]) if cc > 0 else None\n",
    "# axs[0].legend(fontsize=\"x-small\", loc=\"upper right\")\n",
    "axs[0].set_ylabel(r\"$N$ (normalised)\")\n",
    "fig.suptitle(\"Systematics (SF spaxels only)\", y=0.94)\n",
    "\n",
    "if savefigs:\n",
    "    fname = os.path.join(fig_path, f\"hist_KDcomponents_systematic_SF_only.pdf\")\n",
    "    print(f\"Saving to {fname}\")\n",
    "    fig.savefig(fname, bbox_inches=\"tight\", format=\"pdf\")\n",
    "\n",
    "    \n",
    "# Specifically looking at v_grad\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "for cc, col_x in enumerate([\"v_grad (component 0)\", \"v_grad (component 1)\", \"v_grad (component 2)\"]):\n",
    "    for ii in range(3):\n",
    "        cond = df_SF_subset[\"Number of components\"] == ii + 1\n",
    "        if all(df_SF_subset.loc[cond, col_x].isna()):\n",
    "            continue\n",
    "        hist(df_SF_subset.loc[cond, col_x], density=True, histtype=\"step\",\n",
    "             ax=axs[cc],\n",
    "             bins=\"scott\", range=(0, 150),\n",
    "             label=f\"{ncomponents_labels[ii]} KD component{'s' if ii > 1 else ''}\" + r\" ($N = %d$)\" % (df_SF_subset.loc[cond].shape[0]),\n",
    "             color=ncomponents_colours[ii + 1])\n",
    "    axs[cc].set_xlabel(label_fn(col_x) + f\" (component {cc + 1})\")\n",
    "    axs[cc].set_yticklabels([]) if cc > 0 else None\n",
    "    axs[cc].autoscale(enable=True, axis=\"x\", tight=True)\n",
    "# axs[0].legend(fontsize=\"x-small\", loc=\"upper left\")\n",
    "axs[0].set_ylabel(r\"$N$ (normalised)\")\n",
    "fig.suptitle(r\"$v_{\\rm grad}$ (SF spaxels only)\", y=0.94)\n",
    "\n",
    "if savefigs:\n",
    "    fname = os.path.join(fig_path, f\"hist_KDcomponents_vgrad_SF_only.pdf\")\n",
    "    print(f\"Saving to {fname}\")\n",
    "    fig.savefig(fname, bbox_inches=\"tight\", format=\"pdf\")\n",
    "\n",
    "# Local quantities\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "for cc, col_x in enumerate([\"D4000\", \"r/R_e\", \"sigma_*\"]):\n",
    "    for ii in range(3):\n",
    "        cond = df_SF_subset[\"Number of components\"] == ii + 1\n",
    "        hist(df_SF_subset.loc[cond, col_x], density=True, histtype=\"step\",\n",
    "             ax=axs[cc], \n",
    "             range=(vmin_fn(col_x), 100 if col_x.startswith(\"sigma_gas\") else vmax_fn(col_x)),\n",
    "             bins=\"scott\",\n",
    "             label=f\"{ncomponents_labels[ii]} KD component{'s' if ii > 1 else ''}\" + r\" ($N = %d$)\" % (df_SF_subset.loc[cond].shape[0]),\n",
    "             color=ncomponents_colours[ii + 1])\n",
    "    axs[cc].set_xlabel(label_fn(col_x))\n",
    "    axs[cc].set_yticklabels([]) if cc > 0 else None\n",
    "    axs[cc].autoscale(enable=True, axis=\"x\", tight=True)\n",
    "# axs[-1].legend(fontsize=\"x-small\", loc=\"upper right\")\n",
    "axs[0].set_ylabel(r\"$N$ (normalised)\")\n",
    "fig.suptitle(\"Local properties (SF spaxels only)\", y=0.94)\n",
    "\n",
    "# Emission line ratios\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "for cc, col_x in enumerate([\"log O3 (total)\", \"log N2 (total)\", \"log S2 (total)\"]):\n",
    "    for ii in range(3):\n",
    "        cond = df_SF_subset[\"Number of components\"] == ii + 1\n",
    "        hist(df_SF_subset.loc[cond, col_x], density=True, histtype=\"step\",\n",
    "             ax=axs[cc], \n",
    "             range=(vmin_fn(col_x), 100 if col_x.startswith(\"sigma_gas\") else vmax_fn(col_x)),\n",
    "             bins=\"scott\",\n",
    "             label=f\"{ncomponents_labels[ii]} KD component{'s' if ii > 1 else ''}\" + r\" ($N = %d$)\" % (df_SF_subset.loc[cond].shape[0]),\n",
    "             color=ncomponents_colours[ii + 1])\n",
    "    axs[cc].set_xlabel(label_fn(col_x))\n",
    "    axs[cc].set_yticklabels([]) if cc > 0 else None\n",
    "    axs[cc].autoscale(enable=True, axis=\"x\", tight=True)\n",
    "# axs[-1].legend(fontsize=\"x-small\", loc=\"upper right\")\n",
    "axs[0].set_ylabel(r\"$N$ (normalised)\")\n",
    "fig.suptitle(\"Emission line ratios (SF spaxels only)\", y=0.94)\n",
    "\n",
    "# Emission line ratios (metallicity)\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "for cc, col_x in enumerate([\"N2O2 (total)\", \"N2S2 (total)\", \"R23 (total)\"]):\n",
    "    for ii in range(3):\n",
    "        cond = df_SF_subset[\"Number of components\"] == ii + 1\n",
    "        hist(df_SF_subset.loc[cond, col_x], density=True, histtype=\"step\",\n",
    "             ax=axs[cc], \n",
    "             range=(vmin_fn(col_x), 100 if col_x.startswith(\"sigma_gas\") else vmax_fn(col_x)),\n",
    "             bins=\"scott\",\n",
    "             label=f\"{ncomponents_labels[ii]} KD component{'s' if ii > 1 else ''}\" + r\" ($N = %d$)\" % (df_SF_subset.loc[cond].shape[0]),\n",
    "             color=ncomponents_colours[ii + 1])\n",
    "    axs[cc].set_xlabel(label_fn(col_x))\n",
    "    axs[cc].set_yticklabels([]) if cc > 0 else None\n",
    "    axs[cc].autoscale(enable=True, axis=\"x\", tight=True)\n",
    "# axs[-1].legend(fontsize=\"x-small\", loc=\"upper right\")\n",
    "axs[0].set_ylabel(r\"$N$ (normalised)\")\n",
    "fig.suptitle(\"Metallicity-sensitive ratios (SF spaxels only)\", y=0.94)\n",
    "\n",
    "if savefigs:\n",
    "    fname = os.path.join(fig_path, f\"hist_KDcomponents_local_SF_only.pdf\")\n",
    "    print(f\"Saving to {fname}\")\n",
    "    fig.savefig(fname, bbox_inches=\"tight\", format=\"pdf\")\n",
    "\n",
    "# Global quantities\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "for cc, col_x in enumerate([\"R_e (kpc)\", \"log M_*\", \"log(M/R_e)\"]):\n",
    "    for ii in range(3):\n",
    "        cond = df_SF_subset[\"Number of components\"] == ii + 1\n",
    "        hist(df_SF_subset.loc[cond, col_x], density=True, histtype=\"step\",\n",
    "             ax=axs[cc], range=(vmin_fn(col_x), 100 if col_x.startswith(\"sigma\") else vmax_fn(col_x)),\n",
    "             bins=\"scott\",\n",
    "             label=f\"{ncomponents_labels[ii]} KD component{'s' if ii  > 1 else ''}\" + r\" ($N = %d$)\" % (df_SF_subset.loc[cond].shape[0]),\n",
    "             color=ncomponents_colours[ii + 1])\n",
    "    axs[cc].set_xlabel(label_fn(col_x))\n",
    "    axs[cc].set_yticklabels([]) if cc > 0 else None\n",
    "    axs[cc].autoscale(enable=True, axis=\"x\", tight=True)\n",
    "# axs[0].legend(fontsize=\"x-small\", loc=\"upper left\")\n",
    "axs[0].set_ylabel(r\"$N$ (normalised)\")\n",
    "fig.suptitle(\"Global properties (SF spaxels only)\", y=0.94)\n",
    "\n",
    "if savefigs:\n",
    "    fname = os.path.join(fig_path, f\"hist_KDcomponents_global_SF_only.pdf\")\n",
    "    print(f\"Saving to {fname}\")\n",
    "    fig.savefig(fname, bbox_inches=\"tight\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304c94c5ef214e8a95c7773485ce5167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.94, 'Metallicity-sensitive ratios (SF spaxels only)')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Emission line ratios (metallicity)\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 4))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "for cc, col_x in enumerate([\"N2O2 (total)\", \"N2S2 (total)\", \"R23 (total)\", \"O3O2 (total)\"]):\n",
    "    for ii in range(3):\n",
    "        cond = df_SF_subset[\"Number of components\"] == ii + 1\n",
    "        hist(df_SF_subset.loc[cond, col_x], density=True, histtype=\"step\",\n",
    "             ax=axs[cc], \n",
    "             range=(vmin_fn(col_x), vmax_fn(col_x)),\n",
    "             bins=\"scott\",\n",
    "             label=f\"{ncomponents_labels[ii]} KD component{'s' if ii > 1 else ''}\" + r\" ($N = %d$)\" % (df_SF_subset.loc[cond].shape[0]),\n",
    "             color=ncomponents_colours[ii + 1])\n",
    "    axs[cc].set_xlabel(label_fn(col_x))\n",
    "    axs[cc].set_yticklabels([]) if cc > 0 else None\n",
    "    axs[cc].autoscale(enable=True, axis=\"x\", tight=True)\n",
    "# axs[-1].legend(fontsize=\"x-small\", loc=\"upper right\")\n",
    "axs[0].set_ylabel(r\"$N$ (normalised)\")\n",
    "fig.suptitle(\"Metallicity-sensitive ratios (SF spaxels only)\", y=0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"HALPHA extinction correction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis: low-metallicity regions are more likely to exhibit winds\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute how many 1, 2, 3 component spaxels there are in bins of SFR surface density (and SFR)\n",
    "for col_x in [\"log N2 (total)\", \"log O3 (total)\", \"N2O2 (total)\", \"O3O2 (total)\", \"HALPHA extinction correction\", \"D4000\"]:\n",
    "    sfr_vals = np.linspace(vmin_fn(col_x), vmax_fn(col_x), 11)\n",
    "    counts_1 = np.zeros(len(sfr_vals) - 1)\n",
    "    counts_2 = np.zeros(len(sfr_vals) - 1)\n",
    "    counts_3 = np.zeros(len(sfr_vals) - 1)\n",
    "    counts_tot = np.zeros(len(sfr_vals) - 1)\n",
    "\n",
    "    for ll in range(len(sfr_vals) - 1):\n",
    "        cond = df_SF[col_x] > sfr_vals[ll]\n",
    "        cond &= df_SF[col_x] <= sfr_vals[ll + 1]\n",
    "        df_subset = df_SF[cond]\n",
    "        counts_tot[ll] = df_subset.shape[0]\n",
    "        counts_1[ll] = df_subset[df_subset[\"Number of components\"] == 1].shape[0]\n",
    "        counts_2[ll] = df_subset[df_subset[\"Number of components\"] == 2].shape[0]\n",
    "        counts_3[ll] = df_subset[df_subset[\"Number of components\"] == 3].shape[0]\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(7, 8))\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "\n",
    "    # Plot\n",
    "    axs[0].bar(sfr_vals[:-1], counts_1,\n",
    "               align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[1],\n",
    "               label=\"1 components\")\n",
    "    axs[0].bar(sfr_vals[:-1], counts_2, bottom=counts_1,\n",
    "               align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[2],\n",
    "               label=\"2 components\")\n",
    "    axs[0].bar(sfr_vals[:-1], counts_3, bottom=counts_1 + counts_2,\n",
    "               align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[3],\n",
    "               label=\"3 components\")\n",
    "    axs[0].grid()\n",
    "    axs[0].set_ylabel(r\"$N$\")\n",
    "    axs[0].set_yscale(\"log\")\n",
    "    axs[0].autoscale(axis=\"x\", enable=True, tight=True)\n",
    "    axs[0].legend(loc=\"upper right\", fontsize=\"small\")\n",
    "    axs[0].set_ylim([0.5, None])\n",
    "    \n",
    "    axs[1].bar(sfr_vals[:-1], counts_1 / counts_tot  * 100,\n",
    "           align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[1])\n",
    "    axs[1].bar(sfr_vals[:-1], counts_2 / counts_tot  * 100, bottom=counts_1 / counts_tot * 100,\n",
    "           align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[2])\n",
    "    axs[1].bar(sfr_vals[:-1], counts_3 / counts_tot * 100, bottom=counts_1 / counts_tot * 100 + counts_2 / counts_tot * 100,\n",
    "           align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[3])\n",
    "    axs[1].grid()\n",
    "    axs[1].set_ylabel(\"Percentage\")\n",
    "    axs[1].autoscale(axis=\"x\", enable=True, tight=True)\n",
    "    axs[1].autoscale(axis=\"y\", enable=True, tight=True)\n",
    "    axs[1].set_xlabel(label_fn(col_x))\n",
    "\n",
    "    # Heckman+2002 line\n",
    "    if col_x == \"log SFR surface density\":\n",
    "        axs[0].axvline(-1, color=\"k\", linestyle=\"--\")\n",
    "        axs[1].axvline(-1, color=\"k\", linestyle=\"--\")\n",
    "        \n",
    "    if savefigs:\n",
    "        fname = os.path.join(fig_path, f\"hist_SF_only_{col_x.replace(' ', '_')}_ncomponents.pdf\")\n",
    "        print(f\"Saving to {fname}\")\n",
    "        fig.savefig(fname, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute how many 1, 2, 3 component spaxels there are in bins of SFR surface density (and SFR)\n",
    "for col_x in [\"HALPHA S/N (component 0)\", \"HALPHA S/N (component 1)\", \"HALPHA S/N (component 2)\", \"HALPHA S/N (total)\"]:\n",
    "    sfr_vals = np.linspace(vmin_fn(col_x), vmax_fn(col_x), 11)\n",
    "    counts_1 = np.zeros(len(sfr_vals) - 1)\n",
    "    counts_2 = np.zeros(len(sfr_vals) - 1)\n",
    "    counts_3 = np.zeros(len(sfr_vals) - 1)\n",
    "    counts_tot = np.zeros(len(sfr_vals) - 1)\n",
    "\n",
    "    for ll in range(len(sfr_vals) - 1):\n",
    "        cond = df_SF[col_x] > sfr_vals[ll]\n",
    "        cond &= df_SF[col_x] <= sfr_vals[ll + 1]\n",
    "        df_subset = df_SF[cond]\n",
    "        counts_tot[ll] = df_subset.shape[0]\n",
    "        counts_1[ll] = df_subset[df_subset[\"Number of components\"] == 1].shape[0]\n",
    "        counts_2[ll] = df_subset[df_subset[\"Number of components\"] == 2].shape[0]\n",
    "        counts_3[ll] = df_subset[df_subset[\"Number of components\"] == 3].shape[0]\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(7, 8))\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "\n",
    "    # Plot\n",
    "    axs[0].bar(sfr_vals[:-1], counts_1,\n",
    "               align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[1],\n",
    "               label=\"1 components\")\n",
    "    axs[0].bar(sfr_vals[:-1], counts_2, bottom=counts_1,\n",
    "               align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[2],\n",
    "               label=\"2 components\")\n",
    "    axs[0].bar(sfr_vals[:-1], counts_3, bottom=counts_1 + counts_2,\n",
    "               align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[3],\n",
    "               label=\"3 components\")\n",
    "    axs[0].grid()\n",
    "    axs[0].set_ylabel(r\"$N$\")\n",
    "    axs[0].set_yscale(\"log\")\n",
    "    axs[0].autoscale(axis=\"x\", enable=True, tight=True)\n",
    "    axs[0].legend(loc=\"upper right\", fontsize=\"small\")\n",
    "    axs[0].set_ylim([0.5, None])\n",
    "    \n",
    "    axs[1].bar(sfr_vals[:-1], counts_1 / counts_tot  * 100,\n",
    "           align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[1])\n",
    "    axs[1].bar(sfr_vals[:-1], counts_2 / counts_tot  * 100, bottom=counts_1 / counts_tot * 100,\n",
    "           align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[2])\n",
    "    axs[1].bar(sfr_vals[:-1], counts_3 / counts_tot * 100, bottom=counts_1 / counts_tot * 100 + counts_2 / counts_tot * 100,\n",
    "           align=\"edge\", width=np.diff(sfr_vals)[0], color=ncomponents_colours[3])\n",
    "    axs[1].grid()\n",
    "    axs[1].set_ylabel(\"Percentage\")\n",
    "    axs[1].autoscale(axis=\"x\", enable=True, tight=True)\n",
    "    axs[1].autoscale(axis=\"y\", enable=True, tight=True)\n",
    "    axs[1].set_xlabel(label_fn(col_x))\n",
    "\n",
    "    # Heckman+2002 line\n",
    "    if col_x == \"log SFR surface density\":\n",
    "        axs[0].axvline(-1, color=\"k\", linestyle=\"--\")\n",
    "        axs[1].axvline(-1, color=\"k\", linestyle=\"--\")\n",
    "        \n",
    "    if savefigs:\n",
    "        fname = os.path.join(fig_path, f\"hist_SF_only_{col_x.replace(' ', '_')}_ncomponents.pdf\")\n",
    "        print(f\"Saving to {fname}\")\n",
    "        fig.savefig(fname, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What drives the drop in EW as a function of delta sigma in SF galaxies?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_z_list = [\"count\"]\n",
    "for col_z in col_z_list:\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(5 * 3, 5))\n",
    "    fig.subplots_adjust(wspace=0)\n",
    "    bbox = axs[-1].get_position()\n",
    "    cax = fig.add_axes([bbox.x0 + bbox.width, bbox.y0, bbox.width * 0.1, bbox.height])\n",
    "\n",
    "    for ii in range(3):\n",
    "        plot2dhistcontours(df_SF, col_x=f\"log HALPHA continuum luminosity\",\n",
    "                           col_y=f\"log HALPHA EW (component {ii})\",\n",
    "                           col_z=f\"{col_z} (component {ii})\" if f\"{col_z} (component {ii})\" in df_SF else col_z, \n",
    "                           log_z=True if col_z == \"count\" else False,\n",
    "                           alpha=1.0, ax=axs[ii], cax=cax, nbins=100,\n",
    "                           linewidths=0.5,\n",
    "                           contours=True, hist=True, colors=\"white\",\n",
    "                           vmin=1 if col_z == \"count\" else None, \n",
    "                           vmax=1e3 if col_z == \"count\" else None,\n",
    "                           plot_colorbar=True if ii == 3 - 1 else False)\n",
    "        # Decorations\n",
    "        axs[ii].grid()\n",
    "        axs[ii].set_ylabel(\"\") if ii > 0 else None\n",
    "        axs[ii].set_yticklabels([]) if ii > 0 else None\n",
    "        axs[ii].text(s=f\"Component {ii + 1}\", x=0.05, y=0.95, transform=axs[ii].transAxes, verticalalignment=\"top\")\n",
    "   \n",
    "col_z_list = [\"log HALPHA continuum luminosity\"]\n",
    "for col_z in col_z_list:\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(5 * 3, 5))\n",
    "    fig.subplots_adjust(wspace=0)\n",
    "    bbox = axs[-1].get_position()\n",
    "    cax = fig.add_axes([bbox.x0 + bbox.width, bbox.y0, bbox.width * 0.1, bbox.height])\n",
    "\n",
    "    for ii in range(3):\n",
    "        plot2dhistcontours(df=df, \n",
    "                           col_x=f\"log HALPHA luminosity (component {ii})\",\n",
    "                           col_y=f\"log HALPHA EW (component {ii})\",\n",
    "                           col_z=\"count\", log_z=True,\n",
    "                           alpha=0.5, cmap=\"gray_r\",\n",
    "                           ax=axs[ii], plot_colorbar=False)\n",
    "\n",
    "        plot2dhistcontours(df_SF, col_x=f\"log HALPHA luminosity (component {ii})\",\n",
    "                           col_y=f\"log HALPHA EW (component {ii})\",\n",
    "                           col_z=f\"{col_z} (component {ii})\" if f\"{col_z} (component {ii})\" in df_SF else col_z, \n",
    "                           log_z=True if col_z == \"count\" else False,\n",
    "                           alpha=1.0, ax=axs[ii], cax=cax, nbins=100,\n",
    "                           linewidths=0.5,\n",
    "                           contours=True, hist=True, colors=\"white\",\n",
    "                           vmin=1 if col_z == \"count\" else None, \n",
    "                           vmax=1e3 if col_z == \"count\" else None,\n",
    "                           plot_colorbar=True if ii == 3 - 1 else False)\n",
    "        # Decorations\n",
    "        axs[ii].grid()\n",
    "        axs[ii].set_ylabel(\"\") if ii > 0 else None\n",
    "        axs[ii].set_yticklabels([]) if ii > 0 else None\n",
    "        axs[ii].text(s=f\"Component {ii + 1}\", x=0.05, y=0.95, transform=axs[ii].transAxes, verticalalignment=\"top\")\n",
    "   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
